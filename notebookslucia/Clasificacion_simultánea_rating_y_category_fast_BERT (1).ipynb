{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Clasificacion simultánea rating y category_fast-BERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d05ce98bc08c4be392c1993e653713e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_be281969edc34504bb980115d1012646",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_892fd40909994f99bf2619378e72d12a",
              "IPY_MODEL_c01b191871e44a429fea6c30c1b9b03e"
            ]
          }
        },
        "be281969edc34504bb980115d1012646": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "892fd40909994f99bf2619378e72d12a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8e58a48ec4ca4a37900f8d1c2980f2d3",
            "_dom_classes": [],
            "description": " 75%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 75,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_24d2ef02aab5428a9b7c7d95ec45d53e"
          }
        },
        "c01b191871e44a429fea6c30c1b9b03e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_183badd9f6a942248c83313a25182b7c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 75/100 [10:16&lt;03:15,  7.82s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3ca1dddbd204d368aa4d50314f51b8c"
          }
        },
        "8e58a48ec4ca4a37900f8d1c2980f2d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "24d2ef02aab5428a9b7c7d95ec45d53e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "183badd9f6a942248c83313a25182b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3ca1dddbd204d368aa4d50314f51b8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG2GvnXQXSEh"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0UxHhWG8NaBj",
        "outputId": "9464371e-ae18-4d29-9254-0eaf639127c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCSLnOhJNlaf"
      },
      "source": [
        "# Load data\n",
        "import pandas as pd \n",
        "path1 = \"/content/drive/MyDrive/TFG_1/Datasets_procesados/train/amazonEN_train_ml.csv\"\n",
        "path2 = \"/content/drive/MyDrive/TFG_1/Datasets_procesados/valid/amazonEN_valid_ml.csv\"\n",
        "path3 = \"/content/drive/MyDrive/TFG_1/Datasets_procesados/test/amazonEN_test_ml.csv\"\n",
        "df_train = pd.read_csv(path1)\n",
        "df_valid = pd.read_csv(path2)\n",
        "df_test = pd.read_csv(path3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "id": "-MtBOabeNuBr",
        "outputId": "a1dc7069-124b-42c6-84fd-987066967c1e"
      },
      "source": [
        "df_train.head(1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review_id</th>\n",
              "      <th>product_id</th>\n",
              "      <th>reviewer_id</th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>review_title</th>\n",
              "      <th>language</th>\n",
              "      <th>product_category</th>\n",
              "      <th>text_title</th>\n",
              "      <th>text_title_cat</th>\n",
              "      <th>text_cat</th>\n",
              "      <th>product_category_cod</th>\n",
              "      <th>star_rating_str</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>apparel</th>\n",
              "      <th>automotive</th>\n",
              "      <th>baby_product</th>\n",
              "      <th>beauty</th>\n",
              "      <th>book</th>\n",
              "      <th>camera</th>\n",
              "      <th>digital_ebook_purchase</th>\n",
              "      <th>digital_video_download</th>\n",
              "      <th>drugstore</th>\n",
              "      <th>electronics</th>\n",
              "      <th>furniture</th>\n",
              "      <th>grocery</th>\n",
              "      <th>home</th>\n",
              "      <th>home_improvement</th>\n",
              "      <th>industrial_supplies</th>\n",
              "      <th>jewelry</th>\n",
              "      <th>kitchen</th>\n",
              "      <th>lawn_and_garden</th>\n",
              "      <th>luggage</th>\n",
              "      <th>musical_instruments</th>\n",
              "      <th>office_product</th>\n",
              "      <th>other</th>\n",
              "      <th>pc</th>\n",
              "      <th>personal_care_appliances</th>\n",
              "      <th>pet_products</th>\n",
              "      <th>shoes</th>\n",
              "      <th>sports</th>\n",
              "      <th>toy</th>\n",
              "      <th>video_games</th>\n",
              "      <th>watch</th>\n",
              "      <th>wireless</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>en_0953486</td>\n",
              "      <td>product_en_0381770</td>\n",
              "      <td>reviewer_en_0978532</td>\n",
              "      <td>4</td>\n",
              "      <td>Great, great batteries. Arrived on time and pa...</td>\n",
              "      <td>Strip of 10 Fresh Maxell LR1130 Batteries</td>\n",
              "      <td>en</td>\n",
              "      <td>electronics</td>\n",
              "      <td>Strip of 10 Fresh Maxell LR1130 Batteries Grea...</td>\n",
              "      <td>Strip of 10 Fresh Maxell LR1130 Batteries Grea...</td>\n",
              "      <td>Great, great batteries. Arrived on time and pa...</td>\n",
              "      <td>9</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    review_id          product_id  ... watch  wireless\n",
              "0  en_0953486  product_en_0381770  ...     0         0\n",
              "\n",
              "[1 rows x 49 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmH68kuTSYfa",
        "outputId": "01fb5d17-20cc-4a18-9a98-4184ea1b2b5d"
      },
      "source": [
        "df_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200000, 49)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RP9F729XY4m"
      },
      "source": [
        "# Creacion lista de etiquetas \n",
        "  - Todos los nombres, star_rating + product_category"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JNOBmR_gVbbb"
      },
      "source": [
        "multilabels_list = df_train.columns\n",
        "multilabels_list = multilabels_list[13:]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QEuNqbg2rDyQ",
        "outputId": "0ee1b868-5f41-461f-ca76-5923fde9452f"
      },
      "source": [
        "len(multilabels_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vAcVG77yb6q"
      },
      "source": [
        "path4 = \"/content/drive/MyDrive/TFG_1/ml.csv\"\n",
        "df_labels = pd.read_csv(path4)\n",
        "df_labels.to_csv('/content/drive/MyDrive/TFG_1/ml.csv', index=False, header=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITxQrXk-Ucn4"
      },
      "source": [
        "df_train = df_train.head(1000)\n",
        "df_valid = df_valid.head(500)\n",
        "df_test = df_test.head(500)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Qr5hpiNUIbh"
      },
      "source": [
        "# Fast-BERT \n",
        "- importar fast-bert\n",
        "- importar nvidia apex\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DpOC_mV7U2LJ"
      },
      "source": [
        "%%capture\n",
        "!pip install fast-bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLYAq2kEYQHP",
        "outputId": "0df9d5d3-f927-4dd3-b61b-65082df2ae37"
      },
      "source": [
        "!git clone https://github.com/NVIDIA/apex\n",
        "%cd apex\n",
        "!pip install -v --no-cache-dir ./"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'apex' already exists and is not an empty directory.\n",
            "/content/apex\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-2dl_nmcw\n",
            "Created temporary directory: /tmp/pip-req-tracker-qyo_wfku\n",
            "Created requirements tracker '/tmp/pip-req-tracker-qyo_wfku'\n",
            "Created temporary directory: /tmp/pip-install-8lgoqoyf\n",
            "Processing /content/apex\n",
            "  Created temporary directory: /tmp/pip-req-build-nhtr9fp_\n",
            "  Added file:///content/apex to build tracker '/tmp/pip-req-tracker-qyo_wfku'\n",
            "    Running setup.py (path:/tmp/pip-req-build-nhtr9fp_/setup.py) egg_info for package from file:///content/apex\n",
            "    Running command python setup.py egg_info\n",
            "\n",
            "\n",
            "    torch.__version__  = 1.7.0+cu101\n",
            "\n",
            "\n",
            "    running egg_info\n",
            "    creating /tmp/pip-req-build-nhtr9fp_/pip-egg-info/apex.egg-info\n",
            "    writing /tmp/pip-req-build-nhtr9fp_/pip-egg-info/apex.egg-info/PKG-INFO\n",
            "    writing dependency_links to /tmp/pip-req-build-nhtr9fp_/pip-egg-info/apex.egg-info/dependency_links.txt\n",
            "    writing top-level names to /tmp/pip-req-build-nhtr9fp_/pip-egg-info/apex.egg-info/top_level.txt\n",
            "    writing manifest file '/tmp/pip-req-build-nhtr9fp_/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    writing manifest file '/tmp/pip-req-build-nhtr9fp_/pip-egg-info/apex.egg-info/SOURCES.txt'\n",
            "    /tmp/pip-req-build-nhtr9fp_/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "      warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  Source in /tmp/pip-req-build-nhtr9fp_ has version 0.1, which satisfies requirement apex==0.1 from file:///content/apex\n",
            "  Removed apex==0.1 from file:///content/apex from build tracker '/tmp/pip-req-tracker-qyo_wfku'\n",
            "Building wheels for collected packages: apex\n",
            "  Created temporary directory: /tmp/pip-wheel-90nddoa3\n",
            "  Building wheel for apex (setup.py) ... \u001b[?25l  Destination directory: /tmp/pip-wheel-90nddoa3\n",
            "  Running command /usr/bin/python3 -u -c 'import sys, setuptools, tokenize; sys.argv[0] = '\"'\"'/tmp/pip-req-build-nhtr9fp_/setup.py'\"'\"'; __file__='\"'\"'/tmp/pip-req-build-nhtr9fp_/setup.py'\"'\"';f=getattr(tokenize, '\"'\"'open'\"'\"', open)(__file__);code=f.read().replace('\"'\"'\\r\\n'\"'\"', '\"'\"'\\n'\"'\"');f.close();exec(compile(code, __file__, '\"'\"'exec'\"'\"'))' bdist_wheel -d /tmp/pip-wheel-90nddoa3 --python-tag cp36\n",
            "\n",
            "\n",
            "  torch.__version__  = 1.7.0+cu101\n",
            "\n",
            "\n",
            "  /tmp/pip-req-build-nhtr9fp_/setup.py:67: UserWarning: Option --pyprof not specified. Not installing PyProf dependencies!\n",
            "    warnings.warn(\"Option --pyprof not specified. Not installing PyProf dependencies!\")\n",
            "  running bdist_wheel\n",
            "  running build\n",
            "  running build_py\n",
            "  creating build\n",
            "  creating build/lib\n",
            "  creating build/lib/apex\n",
            "  copying apex/__init__.py -> build/lib/apex\n",
            "  creating build/lib/apex/pyprof\n",
            "  copying apex/pyprof/__init__.py -> build/lib/apex/pyprof\n",
            "  creating build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/multi_tensor_apply.py -> build/lib/apex/multi_tensor_apply\n",
            "  copying apex/multi_tensor_apply/__init__.py -> build/lib/apex/multi_tensor_apply\n",
            "  creating build/lib/apex/normalization\n",
            "  copying apex/normalization/fused_layer_norm.py -> build/lib/apex/normalization\n",
            "  copying apex/normalization/__init__.py -> build/lib/apex/normalization\n",
            "  creating build/lib/apex/amp\n",
            "  copying apex/amp/utils.py -> build/lib/apex/amp\n",
            "  copying apex/amp/rnn_compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/compat.py -> build/lib/apex/amp\n",
            "  copying apex/amp/amp.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_initialize.py -> build/lib/apex/amp\n",
            "  copying apex/amp/frontend.py -> build/lib/apex/amp\n",
            "  copying apex/amp/wrap.py -> build/lib/apex/amp\n",
            "  copying apex/amp/scaler.py -> build/lib/apex/amp\n",
            "  copying apex/amp/handle.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_process_optimizer.py -> build/lib/apex/amp\n",
            "  copying apex/amp/opt.py -> build/lib/apex/amp\n",
            "  copying apex/amp/_amp_state.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__version__.py -> build/lib/apex/amp\n",
            "  copying apex/amp/__init__.py -> build/lib/apex/amp\n",
            "  creating build/lib/apex/parallel\n",
            "  copying apex/parallel/LARC.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm_kernel.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/distributed.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/multiproc.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/__init__.py -> build/lib/apex/parallel\n",
            "  copying apex/parallel/optimized_sync_batchnorm.py -> build/lib/apex/parallel\n",
            "  creating build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/weight_norm.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/reparameterization.py -> build/lib/apex/reparameterization\n",
            "  copying apex/reparameterization/__init__.py -> build/lib/apex/reparameterization\n",
            "  creating build/lib/apex/mlp\n",
            "  copying apex/mlp/mlp.py -> build/lib/apex/mlp\n",
            "  copying apex/mlp/__init__.py -> build/lib/apex/mlp\n",
            "  creating build/lib/apex/RNN\n",
            "  copying apex/RNN/cells.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/models.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/RNNBackend.py -> build/lib/apex/RNN\n",
            "  copying apex/RNN/__init__.py -> build/lib/apex/RNN\n",
            "  creating build/lib/apex/contrib\n",
            "  copying apex/contrib/__init__.py -> build/lib/apex/contrib\n",
            "  creating build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adagrad.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_adam.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_novograd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_sgd.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/fused_lamb.py -> build/lib/apex/optimizers\n",
            "  copying apex/optimizers/__init__.py -> build/lib/apex/optimizers\n",
            "  creating build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16_optimizer.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/fp16util.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/loss_scaler.py -> build/lib/apex/fp16_utils\n",
            "  copying apex/fp16_utils/__init__.py -> build/lib/apex/fp16_utils\n",
            "  creating build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/parse.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__main__.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/nvvp.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/db.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/kernel.py -> build/lib/apex/pyprof/parse\n",
            "  copying apex/pyprof/parse/__init__.py -> build/lib/apex/pyprof/parse\n",
            "  creating build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/nvmarker.py -> build/lib/apex/pyprof/nvtx\n",
            "  copying apex/pyprof/nvtx/__init__.py -> build/lib/apex/pyprof/nvtx\n",
            "  creating build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/softmax.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/loss.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__main__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/utility.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pointwise.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/optim.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/prof.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/linear.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/recurrentCell.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/index_slice_join_mutate.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/convert.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/reduction.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/base.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/embedding.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/dropout.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/data.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/blas.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/normalization.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/randomSample.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/output.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/conv.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/pooling.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/misc.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/usage.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/__init__.py -> build/lib/apex/pyprof/prof\n",
            "  copying apex/pyprof/prof/activation.py -> build/lib/apex/pyprof/prof\n",
            "  creating build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/torch_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/tensor_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/functional_overrides.py -> build/lib/apex/amp/lists\n",
            "  copying apex/amp/lists/__init__.py -> build/lib/apex/amp/lists\n",
            "  creating build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/softmax_xentropy.py -> build/lib/apex/contrib/xentropy\n",
            "  copying apex/contrib/xentropy/__init__.py -> build/lib/apex/contrib/xentropy\n",
            "  creating build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/lib/apex/contrib/multihead_attn\n",
            "  copying apex/contrib/multihead_attn/__init__.py -> build/lib/apex/contrib/multihead_attn\n",
            "  creating build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/batch_norm.py -> build/lib/apex/contrib/groupbn\n",
            "  copying apex/contrib/groupbn/__init__.py -> build/lib/apex/contrib/groupbn\n",
            "  creating build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/asp.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/sparse_masklib.py -> build/lib/apex/contrib/sparsity\n",
            "  copying apex/contrib/sparsity/__init__.py -> build/lib/apex/contrib/sparsity\n",
            "  creating build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_adam.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fp16_optimizer.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_sgd.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/fused_lamb.py -> build/lib/apex/contrib/optimizers\n",
            "  copying apex/contrib/optimizers/__init__.py -> build/lib/apex/contrib/optimizers\n",
            "  installing to build/bdist.linux-x86_64/wheel\n",
            "  running install\n",
            "  running install_lib\n",
            "  creating build/bdist.linux-x86_64\n",
            "  creating build/bdist.linux-x86_64/wheel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/parse.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/nvvp.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/db.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/kernel.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  copying build/lib/apex/pyprof/parse/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/parse\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/nvmarker.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  copying build/lib/apex/pyprof/nvtx/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/nvtx\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/softmax.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/loss.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__main__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/utility.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pointwise.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/optim.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/prof.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/linear.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/recurrentCell.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/index_slice_join_mutate.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/convert.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/reduction.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/base.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/embedding.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/dropout.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/data.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/blas.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/normalization.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/randomSample.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/output.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/conv.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/pooling.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/misc.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/usage.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/prof/activation.py -> build/bdist.linux-x86_64/wheel/apex/pyprof/prof\n",
            "  copying build/lib/apex/pyprof/__init__.py -> build/bdist.linux-x86_64/wheel/apex/pyprof\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/multi_tensor_apply.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  copying build/lib/apex/multi_tensor_apply/__init__.py -> build/bdist.linux-x86_64/wheel/apex/multi_tensor_apply\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/fused_layer_norm.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  copying build/lib/apex/normalization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/normalization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/utils.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/rnn_compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/compat.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/torch_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/tensor_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/functional_overrides.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/lists/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp/lists\n",
            "  copying build/lib/apex/amp/amp.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_initialize.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/frontend.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/wrap.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/scaler.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/handle.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_process_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/opt.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/_amp_state.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__version__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  copying build/lib/apex/amp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/amp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/LARC.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm_kernel.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/distributed.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/multiproc.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/__init__.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  copying build/lib/apex/parallel/optimized_sync_batchnorm.py -> build/bdist.linux-x86_64/wheel/apex/parallel\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/weight_norm.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/reparameterization.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  copying build/lib/apex/reparameterization/__init__.py -> build/bdist.linux-x86_64/wheel/apex/reparameterization\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/mlp.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  copying build/lib/apex/mlp/__init__.py -> build/bdist.linux-x86_64/wheel/apex/mlp\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/cells.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/models.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/RNNBackend.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  copying build/lib/apex/RNN/__init__.py -> build/bdist.linux-x86_64/wheel/apex/RNN\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/softmax_xentropy.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  copying build/lib/apex/contrib/xentropy/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/xentropy\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/fast_self_multihead_attn_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/mask_softmax_dropout_func.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/encdec_multihead_attn.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  copying build/lib/apex/contrib/multihead_attn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/multihead_attn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/batch_norm.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  copying build/lib/apex/contrib/groupbn/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/groupbn\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/asp.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/sparse_masklib.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  copying build/lib/apex/contrib/sparsity/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/sparsity\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v3.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/distributed_fused_adam_v2.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib/optimizers\n",
            "  copying build/lib/apex/contrib/__init__.py -> build/bdist.linux-x86_64/wheel/apex/contrib\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adagrad.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_adam.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_novograd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_sgd.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/fused_lamb.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  copying build/lib/apex/optimizers/__init__.py -> build/bdist.linux-x86_64/wheel/apex/optimizers\n",
            "  creating build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16_optimizer.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/fp16util.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/loss_scaler.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/fp16_utils/__init__.py -> build/bdist.linux-x86_64/wheel/apex/fp16_utils\n",
            "  copying build/lib/apex/__init__.py -> build/bdist.linux-x86_64/wheel/apex\n",
            "  running install_egg_info\n",
            "  running egg_info\n",
            "  creating apex.egg-info\n",
            "  writing apex.egg-info/PKG-INFO\n",
            "  writing dependency_links to apex.egg-info/dependency_links.txt\n",
            "  writing top-level names to apex.egg-info/top_level.txt\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  writing manifest file 'apex.egg-info/SOURCES.txt'\n",
            "  Copying apex.egg-info to build/bdist.linux-x86_64/wheel/apex-0.1-py3.6.egg-info\n",
            "  running install_scripts\n",
            "  adding license file \"LICENSE\" (matched pattern \"LICEN[CS]E*\")\n",
            "  creating build/bdist.linux-x86_64/wheel/apex-0.1.dist-info/WHEEL\n",
            "  creating '/tmp/pip-wheel-90nddoa3/apex-0.1-cp36-none-any.whl' and adding 'build/bdist.linux-x86_64/wheel' to it\n",
            "  adding 'apex/__init__.py'\n",
            "  adding 'apex/RNN/RNNBackend.py'\n",
            "  adding 'apex/RNN/__init__.py'\n",
            "  adding 'apex/RNN/cells.py'\n",
            "  adding 'apex/RNN/models.py'\n",
            "  adding 'apex/amp/__init__.py'\n",
            "  adding 'apex/amp/__version__.py'\n",
            "  adding 'apex/amp/_amp_state.py'\n",
            "  adding 'apex/amp/_initialize.py'\n",
            "  adding 'apex/amp/_process_optimizer.py'\n",
            "  adding 'apex/amp/amp.py'\n",
            "  adding 'apex/amp/compat.py'\n",
            "  adding 'apex/amp/frontend.py'\n",
            "  adding 'apex/amp/handle.py'\n",
            "  adding 'apex/amp/opt.py'\n",
            "  adding 'apex/amp/rnn_compat.py'\n",
            "  adding 'apex/amp/scaler.py'\n",
            "  adding 'apex/amp/utils.py'\n",
            "  adding 'apex/amp/wrap.py'\n",
            "  adding 'apex/amp/lists/__init__.py'\n",
            "  adding 'apex/amp/lists/functional_overrides.py'\n",
            "  adding 'apex/amp/lists/tensor_overrides.py'\n",
            "  adding 'apex/amp/lists/torch_overrides.py'\n",
            "  adding 'apex/contrib/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/__init__.py'\n",
            "  adding 'apex/contrib/groupbn/batch_norm.py'\n",
            "  adding 'apex/contrib/multihead_attn/__init__.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_encdec_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/fast_self_multihead_attn_norm_add_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/mask_softmax_dropout_func.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn.py'\n",
            "  adding 'apex/contrib/multihead_attn/self_multihead_attn_func.py'\n",
            "  adding 'apex/contrib/optimizers/__init__.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v2.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_adam_v3.py'\n",
            "  adding 'apex/contrib/optimizers/distributed_fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fp16_optimizer.py'\n",
            "  adding 'apex/contrib/optimizers/fused_adam.py'\n",
            "  adding 'apex/contrib/optimizers/fused_lamb.py'\n",
            "  adding 'apex/contrib/optimizers/fused_sgd.py'\n",
            "  adding 'apex/contrib/sparsity/__init__.py'\n",
            "  adding 'apex/contrib/sparsity/asp.py'\n",
            "  adding 'apex/contrib/sparsity/sparse_masklib.py'\n",
            "  adding 'apex/contrib/xentropy/__init__.py'\n",
            "  adding 'apex/contrib/xentropy/softmax_xentropy.py'\n",
            "  adding 'apex/fp16_utils/__init__.py'\n",
            "  adding 'apex/fp16_utils/fp16_optimizer.py'\n",
            "  adding 'apex/fp16_utils/fp16util.py'\n",
            "  adding 'apex/fp16_utils/loss_scaler.py'\n",
            "  adding 'apex/mlp/__init__.py'\n",
            "  adding 'apex/mlp/mlp.py'\n",
            "  adding 'apex/multi_tensor_apply/__init__.py'\n",
            "  adding 'apex/multi_tensor_apply/multi_tensor_apply.py'\n",
            "  adding 'apex/normalization/__init__.py'\n",
            "  adding 'apex/normalization/fused_layer_norm.py'\n",
            "  adding 'apex/optimizers/__init__.py'\n",
            "  adding 'apex/optimizers/fused_adagrad.py'\n",
            "  adding 'apex/optimizers/fused_adam.py'\n",
            "  adding 'apex/optimizers/fused_lamb.py'\n",
            "  adding 'apex/optimizers/fused_novograd.py'\n",
            "  adding 'apex/optimizers/fused_sgd.py'\n",
            "  adding 'apex/parallel/LARC.py'\n",
            "  adding 'apex/parallel/__init__.py'\n",
            "  adding 'apex/parallel/distributed.py'\n",
            "  adding 'apex/parallel/multiproc.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm.py'\n",
            "  adding 'apex/parallel/optimized_sync_batchnorm_kernel.py'\n",
            "  adding 'apex/parallel/sync_batchnorm.py'\n",
            "  adding 'apex/parallel/sync_batchnorm_kernel.py'\n",
            "  adding 'apex/pyprof/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/__init__.py'\n",
            "  adding 'apex/pyprof/nvtx/nvmarker.py'\n",
            "  adding 'apex/pyprof/parse/__init__.py'\n",
            "  adding 'apex/pyprof/parse/__main__.py'\n",
            "  adding 'apex/pyprof/parse/db.py'\n",
            "  adding 'apex/pyprof/parse/kernel.py'\n",
            "  adding 'apex/pyprof/parse/nvvp.py'\n",
            "  adding 'apex/pyprof/parse/parse.py'\n",
            "  adding 'apex/pyprof/prof/__init__.py'\n",
            "  adding 'apex/pyprof/prof/__main__.py'\n",
            "  adding 'apex/pyprof/prof/activation.py'\n",
            "  adding 'apex/pyprof/prof/base.py'\n",
            "  adding 'apex/pyprof/prof/blas.py'\n",
            "  adding 'apex/pyprof/prof/conv.py'\n",
            "  adding 'apex/pyprof/prof/convert.py'\n",
            "  adding 'apex/pyprof/prof/data.py'\n",
            "  adding 'apex/pyprof/prof/dropout.py'\n",
            "  adding 'apex/pyprof/prof/embedding.py'\n",
            "  adding 'apex/pyprof/prof/index_slice_join_mutate.py'\n",
            "  adding 'apex/pyprof/prof/linear.py'\n",
            "  adding 'apex/pyprof/prof/loss.py'\n",
            "  adding 'apex/pyprof/prof/misc.py'\n",
            "  adding 'apex/pyprof/prof/normalization.py'\n",
            "  adding 'apex/pyprof/prof/optim.py'\n",
            "  adding 'apex/pyprof/prof/output.py'\n",
            "  adding 'apex/pyprof/prof/pointwise.py'\n",
            "  adding 'apex/pyprof/prof/pooling.py'\n",
            "  adding 'apex/pyprof/prof/prof.py'\n",
            "  adding 'apex/pyprof/prof/randomSample.py'\n",
            "  adding 'apex/pyprof/prof/recurrentCell.py'\n",
            "  adding 'apex/pyprof/prof/reduction.py'\n",
            "  adding 'apex/pyprof/prof/softmax.py'\n",
            "  adding 'apex/pyprof/prof/usage.py'\n",
            "  adding 'apex/pyprof/prof/utility.py'\n",
            "  adding 'apex/reparameterization/__init__.py'\n",
            "  adding 'apex/reparameterization/reparameterization.py'\n",
            "  adding 'apex/reparameterization/weight_norm.py'\n",
            "  adding 'apex-0.1.dist-info/LICENSE'\n",
            "  adding 'apex-0.1.dist-info/METADATA'\n",
            "  adding 'apex-0.1.dist-info/WHEEL'\n",
            "  adding 'apex-0.1.dist-info/top_level.txt'\n",
            "  adding 'apex-0.1.dist-info/RECORD'\n",
            "  removing build/bdist.linux-x86_64/wheel\n",
            "\u001b[?25hdone\n",
            "  Created wheel for apex: filename=apex-0.1-cp36-none-any.whl size=194551 sha256=e7d5a8077c4ba406b47bf5b6a5fa1d7da22cf124f55655f85523d68a2bf0ae3b\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-2dl_nmcw/wheels/b1/3a/aa/d84906eaab780ae580c7a5686a33bf2820d8590ac3b60d5967\n",
            "  Removing source in /tmp/pip-req-build-nhtr9fp_\n",
            "Successfully built apex\n",
            "Installing collected packages: apex\n",
            "  Found existing installation: apex 0.1\n",
            "    Uninstalling apex-0.1:\n",
            "      Created temporary directory: /usr/local/lib/python3.6/dist-packages/~pex-0.1.dist-info\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex-0.1.dist-info/\n",
            "      Created temporary directory: /usr/local/lib/python3.6/dist-packages/~pex\n",
            "      Removing file or directory /usr/local/lib/python3.6/dist-packages/apex/\n",
            "      Successfully uninstalled apex-0.1\n",
            "\n",
            "Successfully installed apex-0.1\n",
            "Cleaning up...\n",
            "Removed build tracker '/tmp/pip-req-tracker-qyo_wfku'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UKh5mggqXtEl"
      },
      "source": [
        "# Modelo Fast-BERT for multilabel classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWERUEbIU7WU"
      },
      "source": [
        "from fast_bert.data_cls import BertDataBunch\n",
        "\n",
        "# Creación objeto DataBunch\n",
        "\n",
        "DATA_PATH = \"/content/drive/MyDrive/TFG_1\"\n",
        "LABEL_PATH= \"/content/drive/MyDrive/TFG_1\"\n",
        "\n",
        "databunch = BertDataBunch(DATA_PATH, LABEL_PATH,\n",
        "                          tokenizer='bert-base-uncased',\n",
        "                          train_file='train_ml.csv',\n",
        "                          val_file='valid_ml.csv',\n",
        "                          label_file='ml.csv',          #CSV con los nombres de las labels \n",
        "                          text_col='review_body',\n",
        "                          label_col= multilabels_list,  # Lista de las labels posibles\n",
        "                          batch_size_per_gpu=16,\n",
        "                          max_seq_length=512,\n",
        "                          multi_gpu=True,\n",
        "                          multi_label=True,             # True para multilabel clasification\n",
        "                          model_type='bert')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PNYj4DX_VrY-",
        "outputId": "3b03e2d6-7fdd-4351-89b0-2c5a94676783"
      },
      "source": [
        "from fast_bert.learner_cls import BertLearner\n",
        "from fast_bert.metrics import accuracy\n",
        "from fast_bert.metrics import roc_auc, roc_curve\n",
        "import logging\n",
        "import torch \n",
        "\n",
        "# Creación objeto Learner \n",
        "\n",
        "logger = logging.getLogger()\n",
        "device_cuda = torch.device(\"cuda\")\n",
        "metrics = [{'name': 'accuracy', 'function': accuracy}]\n",
        "\n",
        "\n",
        "OUTPUT_DIR = \"/content/drive/MyDrive/TFG_1/Modelos_entrenados/fast_bert_ml\"\n",
        "\n",
        "\n",
        "learner = BertLearner.from_pretrained_model(\n",
        "\t\t\t\t\t\tdatabunch,\n",
        "\t\t\t\t\t\tpretrained_path='bert-base-uncased',\n",
        "\t\t\t\t\t\tmetrics=metrics,\n",
        "\t\t\t\t\t\tdevice=device_cuda,\n",
        "\t\t\t\t\t\tlogger=logger,\n",
        "\t\t\t\t\t\toutput_dir=OUTPUT_DIR,\n",
        "\t\t\t\t\t\tfinetuned_wgts_path=None,\n",
        "\t\t\t\t\t\twarmup_steps=500,\n",
        "\t\t\t\t\t\tmulti_gpu=True,\n",
        "\t\t\t\t\t\tis_fp16=True,\n",
        "\t\t\t\t\t\tmulti_label=True,\n",
        "\t\t\t\t\t\tlogging_steps=50)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMultiLabelSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForMultiLabelSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForMultiLabelSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 726,
          "referenced_widgets": [
            "d05ce98bc08c4be392c1993e653713e9",
            "be281969edc34504bb980115d1012646",
            "892fd40909994f99bf2619378e72d12a",
            "c01b191871e44a429fea6c30c1b9b03e",
            "8e58a48ec4ca4a37900f8d1c2980f2d3",
            "24d2ef02aab5428a9b7c7d95ec45d53e",
            "183badd9f6a942248c83313a25182b7c",
            "b3ca1dddbd204d368aa4d50314f51b8c"
          ]
        },
        "id": "D2wCGXMsW_Yp",
        "outputId": "3123f771-1b01-45da-a17d-13e3a642629a"
      },
      "source": [
        "#Buscador de Learning Rate óptima\n",
        "\n",
        "learner.lr_find(start_lr=1e-5,optimizer_type='adamw')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Warning:  multi_tensor_applier fused unscale kernel is unavailable, possibly because apex was installed without --cuda_ext --cpp_ext. Using Python fallback.  Original ImportError was: ModuleNotFoundError(\"No module named 'amp_C'\",)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d05ce98bc08c4be392c1993e653713e9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Stopping early, the loss has diverged\n",
            "Learning rate search finished. See the graph with {finder_name}.plot()\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-dCBmtaV8dp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "75862dd3-58da-4a25-e5ce-7a987611b2d4"
      },
      "source": [
        "# Entrenamiento del modelo \n",
        "\n",
        "learner.fit(epochs=1,\n",
        "\t\t\tlr=10e-2,        # Learning rate escogida como optima\n",
        "\t\t\tvalidate=True, \t# Evaluate the model after each epoch\n",
        "\t\t\tschedule_type=\"warmup_cosine\",\n",
        "\t\t\toptimizer_type=\"adamw\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Selected optimization level O1:  Insert automatic casts around Pytorch functions and Tensor methods.\n",
            "\n",
            "Defaults for this optimization level are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n",
            "Processing user overrides (additional kwargs that are not None)...\n",
            "After processing overrides, optimization options are:\n",
            "enabled                : True\n",
            "opt_level              : O1\n",
            "cast_model_type        : None\n",
            "patch_torch_functions  : True\n",
            "keep_batchnorm_fp32    : None\n",
            "master_weights         : None\n",
            "loss_scale             : dynamic\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/optim/lr_scheduler.py:247: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
            "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32768.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16384.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8192.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4096.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2048.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1024.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 512.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 256.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 128.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 64.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 32.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 16.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.5\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.25\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0625\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.03125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.015625\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0078125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00390625\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.001953125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0009765625\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.00048828125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.000244140625\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 0.0001220703125\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.103515625e-05\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0517578125e-05\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.52587890625e-05\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.62939453125e-06\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.814697265625e-06\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9073486328125e-06\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.5367431640625e-07\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.76837158203125e-07\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.384185791015625e-07\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1920928955078125e-07\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.960464477539063e-08\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9802322387695312e-08\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4901161193847656e-08\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.450580596923828e-09\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.725290298461914e-09\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.862645149230957e-09\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.313225746154785e-10\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.656612873077393e-10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3283064365386963e-10\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1641532182693481e-10\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.820766091346741e-11\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.9103830456733704e-11\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4551915228366852e-11\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.275957614183426e-12\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.637978807091713e-12\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8189894035458565e-12\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.094947017729282e-13\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.547473508864641e-13\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2737367544323206e-13\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1368683772161603e-13\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.684341886080802e-14\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.842170943040401e-14\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4210854715202004e-14\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.105427357601002e-15\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.552713678800501e-15\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7763568394002505e-15\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.881784197001252e-16\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.440892098500626e-16\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.220446049250313e-16\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1102230246251565e-16\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.551115123125783e-17\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7755575615628914e-17\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3877787807814457e-17\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.938893903907228e-18\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.469446951953614e-18\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.734723475976807e-18\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.673617379884035e-19\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.336808689942018e-19\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.168404344971009e-19\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0842021724855044e-19\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.421010862427522e-20\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.710505431213761e-20\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3552527156068805e-20\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.776263578034403e-21\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3881317890172014e-21\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6940658945086007e-21\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.470329472543003e-22\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.235164736271502e-22\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.117582368135751e-22\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0587911840678754e-22\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.293955920339377e-23\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6469779601696886e-23\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3234889800848443e-23\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.617444900424222e-24\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.308722450212111e-24\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6543612251060553e-24\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.271806125530277e-25\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.1359030627651384e-25\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0679515313825692e-25\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0339757656912846e-25\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.169878828456423e-26\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5849394142282115e-26\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2924697071141057e-26\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.462348535570529e-27\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2311742677852644e-27\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6155871338926322e-27\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.077935669463161e-28\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.0389678347315804e-28\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0194839173657902e-28\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0097419586828951e-28\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.048709793414476e-29\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.524354896707238e-29\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.262177448353619e-29\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.310887241768095e-30\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1554436208840472e-30\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5777218104420236e-30\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.888609052210118e-31\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.944304526105059e-31\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9721522630525295e-31\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.860761315262648e-32\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.930380657631324e-32\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.465190328815662e-32\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.232595164407831e-32\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.162975822039155e-33\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0814879110195774e-33\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5407439555097887e-33\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.703719777548943e-34\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.851859888774472e-34\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.925929944387236e-34\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.62964972193618e-35\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.81482486096809e-35\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.407412430484045e-35\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2037062152420224e-35\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.018531076210112e-36\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.009265538105056e-36\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.504632769052528e-36\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.52316384526264e-37\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.76158192263132e-37\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.88079096131566e-37\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.4039548065783e-38\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.70197740328915e-38\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.350988701644575e-38\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1754943508222875e-38\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.877471754111438e-39\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.938735877055719e-39\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4693679385278594e-39\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.346839692639297e-40\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.6734198463196485e-40\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8367099231598242e-40\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.183549615799121e-41\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.591774807899561e-41\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2958874039497803e-41\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1479437019748901e-41\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.739718509874451e-42\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8698592549372254e-42\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4349296274686127e-42\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.174648137343064e-43\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.587324068671532e-43\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.793662034335766e-43\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.96831017167883e-44\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.484155085839415e-44\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2420775429197073e-44\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1210387714598537e-44\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.605193857299268e-45\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.802596928649634e-45\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.401298464324817e-45\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.006492321624085e-46\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.503246160812043e-46\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7516230804060213e-46\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.758115402030107e-47\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3790577010150533e-47\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1895288505075267e-47\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0947644252537633e-47\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.473822126268817e-48\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7369110631344083e-48\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3684555315672042e-48\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.842277657836021e-49\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.4211388289180104e-49\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7105694144590052e-49\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.552847072295026e-50\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.276423536147513e-50\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1382117680737565e-50\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0691058840368783e-50\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.345529420184391e-51\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.6727647100921956e-51\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3363823550460978e-51\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.681911775230489e-52\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3409558876152446e-52\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6704779438076223e-52\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.352389719038111e-53\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.176194859519056e-53\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.088097429759528e-53\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.044048714879764e-53\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.22024357439882e-54\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.61012178719941e-54\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.305060893599705e-54\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.525304467998525e-55\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2626522339992623e-55\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6313261169996311e-55\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.156630584998156e-56\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.078315292499078e-56\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.039157646249539e-56\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0195788231247695e-56\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.0978941156238473e-57\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5489470578119236e-57\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2744735289059618e-57\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.372367644529809e-58\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.1861838222649046e-58\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5930919111324523e-58\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.965459555662261e-59\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.982729777831131e-59\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9913648889155653e-59\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.956824444577827e-60\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.9784122222889134e-60\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4892061111444567e-60\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2446030555722283e-60\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.223015277861142e-61\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.111507638930571e-61\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5557538194652854e-61\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.778769097326427e-62\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.8893845486632136e-62\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9446922743316068e-62\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.723461371658034e-63\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.861730685829017e-63\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4308653429145085e-63\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2154326714572542e-63\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.077163357286271e-64\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.0385816786431356e-64\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5192908393215678e-64\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.596454196607839e-65\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7982270983039195e-65\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8991135491519597e-65\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.495567745759799e-66\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.7477838728798994e-66\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3738919364399497e-66\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1869459682199748e-66\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.934729841099874e-67\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.967364920549937e-67\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4836824602749686e-67\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.418412301374843e-68\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.7092061506874214e-68\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8546030753437107e-68\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.273015376718553e-69\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.636507688359277e-69\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3182538441796384e-69\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1591269220898192e-69\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.795634610449096e-70\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.897817305224548e-70\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.448908652612274e-70\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.24454326306137e-71\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.622271631530685e-71\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8111358157653425e-71\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.055679078826712e-72\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.527839539413356e-72\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.263919769706678e-72\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.131959884853339e-72\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.659799424266695e-73\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8298997121333476e-73\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4149498560666738e-73\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.074749280333369e-74\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5373746401666845e-74\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7686873200833423e-74\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.843436600416711e-75\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.421718300208356e-75\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.210859150104178e-75\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.105429575052089e-75\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.527147875260445e-76\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7635739376302223e-76\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3817869688151111e-76\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.908934844075556e-77\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.454467422037778e-77\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.727233711018889e-77\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.636168555094445e-78\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3180842775472223e-78\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1590421387736112e-78\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0795210693868056e-78\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.397605346934028e-79\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.698802673467014e-79\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.349401336733507e-79\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.747006683667535e-80\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.3735033418337674e-80\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6867516709168837e-80\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.433758354584419e-81\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.2168791772922093e-81\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1084395886461046e-81\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0542197943230523e-81\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.271098971615262e-82\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.635549485807631e-82\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3177747429038154e-82\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.588873714519077e-83\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.2944368572595385e-83\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.6472184286297693e-83\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.236092143148846e-84\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.118046071574423e-84\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.0590230357872116e-84\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0295115178936058e-84\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.147557589468029e-85\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.5737787947340145e-85\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2868893973670072e-85\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.434446986835036e-86\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.217223493417518e-86\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.608611746708759e-86\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.043058733543795e-87\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.021529366771898e-87\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.010764683385949e-87\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0053823416929744e-87\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.026911708464872e-88\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.513455854232436e-88\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.256727927116218e-88\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.28363963558109e-89\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.141819817790545e-89\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5709099088952725e-89\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.854549544476363e-90\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.9272747722381812e-90\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9636373861190906e-90\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.818186930595453e-91\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.909093465297727e-91\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.4545467326488633e-91\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.2272733663244316e-91\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.136366831622158e-92\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.068183415811079e-92\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.5340917079055395e-92\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.670458539527698e-93\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.835229269763849e-93\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.9176146348819244e-93\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.588073174409622e-94\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.794036587204811e-94\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3970182936024055e-94\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1985091468012028e-94\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.992545734006014e-95\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.996272867003007e-95\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4981364335015035e-95\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.490682167507517e-96\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.745341083753759e-96\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.8726705418768793e-96\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.363352709384397e-97\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.6816763546921983e-97\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.3408381773460992e-97\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1704190886730496e-97\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.852095443365248e-98\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.926047721682624e-98\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.463023860841312e-98\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.31511930420656e-99\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.65755965210328e-99\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.82877982605164e-99\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 9.1438991302582e-100\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.5719495651291e-100\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.28597478256455e-100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:root:NaN or Inf found in input tensor.\n",
            "WARNING:root:NaN or Inf found in input tensor.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.142987391282275e-100\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.714936956411375e-101\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.8574684782056875e-101\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.4287342391028437e-101\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 7.143671195514219e-102\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.5718355977571093e-102\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7859177988785547e-102\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.929588994392773e-103\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.464794497196387e-103\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.2323972485981933e-103\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.1161986242990967e-103\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.5809931214954833e-104\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7904965607477417e-104\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3952482803738708e-104\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.976241401869354e-105\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 3.488120700934677e-105\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.7440603504673385e-105\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 8.720301752336693e-106\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 4.3601508761683463e-106\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.1800754380841732e-106\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.0900377190420866e-106\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 5.450188595210433e-107\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 2.7250942976052165e-107\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 1.3625471488026082e-107\n",
            "Gradient overflow.  Skipping step, loss scaler 0 reducing loss scale to 6.812735744013041e-108\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='16' class='' max='16' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.00% [16/16 00:07<00:00]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(625, nan)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDh0RbsPW1FW"
      },
      "source": [
        "# Guardar el modelo\n",
        "\n",
        "learner.save_model()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8hiv-LZYPhS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STwYQtUuYQgA"
      },
      "source": [
        "# Evaluación del Modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PT9zBvJC8Kti",
        "outputId": "9705208c-ecec-4b9f-f00a-cefba6234b4f"
      },
      "source": [
        "texts = ['I really love this chair product']\n",
        "predictions = learner.predict_batch(texts)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:1490: FutureWarning: Using short name for 'orient' is deprecated. Only the options: ('dict', list, 'series', 'split', 'records', 'index') will be used in a future version. Use one of the above to silence this warning.\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPN9SzSF8XRg",
        "outputId": "5501782a-8450-4991-9008-2356afea0b19"
      },
      "source": [
        "predictions   ## todo es NaN, no puede estar funcionando bien "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('0', nan),\n",
              "  ('1', nan),\n",
              "  ('2', nan),\n",
              "  ('3', nan),\n",
              "  ('4', nan),\n",
              "  ('apparel', nan),\n",
              "  ('automotive', nan),\n",
              "  ('baby_product', nan),\n",
              "  ('beauty', nan),\n",
              "  ('book', nan),\n",
              "  ('camera', nan),\n",
              "  ('digital_ebook_purchase', nan),\n",
              "  ('digital_video_download', nan),\n",
              "  ('drugstore', nan),\n",
              "  ('electronics', nan),\n",
              "  ('furniture', nan),\n",
              "  ('grocery', nan),\n",
              "  ('home', nan),\n",
              "  ('home_improvement', nan),\n",
              "  ('industrial_supplies', nan),\n",
              "  ('jewelry', nan),\n",
              "  ('kitchen', nan),\n",
              "  ('lawn_and_garden', nan),\n",
              "  ('luggage', nan),\n",
              "  ('musical_instruments', nan),\n",
              "  ('office_product', nan),\n",
              "  ('other', nan),\n",
              "  ('pc', nan),\n",
              "  ('personal_care_appliances', nan),\n",
              "  ('pet_products', nan),\n",
              "  ('shoes', nan),\n",
              "  ('sports', nan),\n",
              "  ('toy', nan),\n",
              "  ('video_games', nan),\n",
              "  ('watch', nan),\n",
              "  ('wireless', nan)]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9QHQdpml8Y8q",
        "outputId": "d8ccbf5a-96c3-498e-ceab-50709f05c6f6"
      },
      "source": [
        "!pip install tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (2.4.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.3.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.4.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.32.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.36.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (53.0.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (0.10.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard) (1.25.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard) (3.4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard) (3.4.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KEnQJk19Iac",
        "outputId": "886179d7-7b08-4d8d-aa29-7216387e7198"
      },
      "source": [
        "#!tensorboard --logdir=/content/drive/MyDrive/Modelos_entrenados/fast_bert_ml/tensorboard"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-22 13:37:47.810285: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
            "TensorBoard 2.4.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7HZrGd-c9Mx7"
      },
      "source": [
        "from fast_bert.prediction import BertClassificationPredictor\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "9kixja1vD6Ym",
        "outputId": "874e4e42-49df-4b28-a4a9-2779bd0d954b"
      },
      "source": [
        "predictor = BertClassificationPredictor(args.output_dir/'model_out', args.output_dir, \"/content/drive/MyDrive/TFG_1/ml.csv\", \n",
        "                                        multi_label=True, model_type='bert', do_lower_case=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-ee9a2cea9841>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m predictor = BertClassificationPredictor(args.output_dir/'model_out', args.output_dir, \"/content/drive/MyDrive/TFG_1/ml.csv\", \n\u001b[0m\u001b[1;32m      2\u001b[0m                                         multi_label=True, model_type='bert', do_lower_case=False)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSLaRc85EN6M"
      },
      "source": [
        "output = predictor.predict_batch(list(pd.read_csv(\"../data/test.csv\")['comment_text'].values))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AUP85DIcEc3B"
      },
      "source": [
        "pd.DataFrame(output).to_csv('../data/output_xlnet.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDT2IY0WEdlp"
      },
      "source": [
        "results = pd.read_csv('../data/output_xlnet.csv')\n",
        "preds = pd.DataFrame([{item[0]: item[1] for item in pred} for pred in output])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IsxRfnS1EkiX"
      },
      "source": [
        "preds.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zp25YXMBEn4j"
      },
      "source": [
        "test_df = pd.read_csv(\"../data/train.csv\")\n",
        "test_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}