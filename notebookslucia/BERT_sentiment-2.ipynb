{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "BERT_sentiment.ipynb",
      "provenance": []
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8e8f9c61770c421f99caf888151d7709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2324fd6dbb484e6bbac2aaf21195cd7d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_26bf23e62c2e4e29b52d98763942093c",
              "IPY_MODEL_90db4328999a42bfb2142e3ef6ef3fcf"
            ]
          }
        },
        "2324fd6dbb484e6bbac2aaf21195cd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "26bf23e62c2e4e29b52d98763942093c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5a2dcab29d134b3ca840a445ba8e758b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5769c72b3cc44553861d42ae37e434dc"
          }
        },
        "90db4328999a42bfb2142e3ef6ef3fcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7dfca9ed4b3547ecbb85de5f8e9c9577",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 629kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c1677052ec8340fdadd420dbd3bff3b1"
          }
        },
        "5a2dcab29d134b3ca840a445ba8e758b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5769c72b3cc44553861d42ae37e434dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7dfca9ed4b3547ecbb85de5f8e9c9577": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c1677052ec8340fdadd420dbd3bff3b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07fa3ac342244e669ae1bb2e9d5fb1a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_673502a40074410291fe85c11c138d1b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d0c6c33e034d43d4a8a2e99d16d100bd",
              "IPY_MODEL_2ac65446b8484166b7004678416453de"
            ]
          }
        },
        "673502a40074410291fe85c11c138d1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d0c6c33e034d43d4a8a2e99d16d100bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4db59796c27c4d73ae584a04cee3c98e",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5630810522334199b1ee9e0c913fa4f9"
          }
        },
        "2ac65446b8484166b7004678416453de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e93859e25f1548e8aa64a7b0d55614f1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:06&lt;00:00, 67.9B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_42dc53270f324ddba91a19dc0a89683b"
          }
        },
        "4db59796c27c4d73ae584a04cee3c98e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5630810522334199b1ee9e0c913fa4f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e93859e25f1548e8aa64a7b0d55614f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "42dc53270f324ddba91a19dc0a89683b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "07477a4449414f3bb867d24e88f38de3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_850ba750be4d4ce88013b94b705b1401",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_df4340a5de7e4863a08e1b61836cb52b",
              "IPY_MODEL_952f139896f9451eb7a1c21a7b5b2ddd"
            ]
          }
        },
        "850ba750be4d4ce88013b94b705b1401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "df4340a5de7e4863a08e1b61836cb52b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2ccfd1a533374af185713666915094ee",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6f50df78629243c9a2056d5768a60b0c"
          }
        },
        "952f139896f9451eb7a1c21a7b5b2ddd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d85f122dee7240a28f5151c2b5a19499",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:05&lt;00:00, 77.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_138ff7843bef474a8c6844e95be9c574"
          }
        },
        "2ccfd1a533374af185713666915094ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6f50df78629243c9a2056d5768a60b0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d85f122dee7240a28f5151c2b5a19499": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "138ff7843bef474a8c6844e95be9c574": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pJkEqFl-QtCB"
      },
      "source": [
        "## libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i25B-WAdQ2Xd",
        "outputId": "16c24c82-6abe-43b1-bcd9-b258e52358b9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ez0cPI2CQtCI"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import urllib\n",
        "import collections\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBx6CxopQtCJ"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4CXVch8QtCJ",
        "outputId": "55c93718-d928-44c4-caaa-bcef92f1ac55"
      },
      "source": [
        "import torch\n",
        "\n",
        "# If there's a GPU available...\n",
        "if torch.cuda.is_available():    \n",
        "\n",
        "    # Tell PyTorch to use the GPU.    \n",
        "    device = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "\n",
        "# If not...\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nGET6NMYQtCK"
      },
      "source": [
        "## process data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA33jvNfQtCL"
      },
      "source": [
        "path = \"drive/MyDrive/dataset_en_train.json\"\n",
        "df = pd.read_json(path, lines = True).rename(columns={'stars':'star_rating'})"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I8rQmfgWQtCL",
        "outputId": "438b60b2-8f03-411c-fa5a-a88407020945"
      },
      "source": [
        "df = df[['star_rating','review_body','product_category']]\n",
        "df = df.dropna()\n",
        "df['star_rating']= np.where(df['star_rating']>=4,1,0) ##asi un poco mas balanceado \n",
        "#df = df.head(10000)\n",
        "print ((df['star_rating'] == 0).sum())\n",
        "print ((df['star_rating'] == 1).sum())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000\n",
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cnhcgFs2QtCL",
        "outputId": "5d6834b9-eea9-4ce9-b2d2-c7502ceb03cd"
      },
      "source": [
        "INPUT_FEATURE = 'review_body'\n",
        "OUTPUT_FEATURE = 'star_rating'\n",
        "\n",
        "X = df[INPUT_FEATURE].values\n",
        "y = df[OUTPUT_FEATURE].values\n",
        "df.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>star_rating</th>\n",
              "      <th>review_body</th>\n",
              "      <th>product_category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Arrived broken. Manufacturer defect. Two of th...</td>\n",
              "      <td>furniture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>the cabinet dot were all detached from backing...</td>\n",
              "      <td>home_improvement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>I received my first order of this product and ...</td>\n",
              "      <td>home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>This product is a piece of shit. Do not buy. D...</td>\n",
              "      <td>wireless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>went through 3 in one day doesn't fit correct ...</td>\n",
              "      <td>pc</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   star_rating  ...  product_category\n",
              "0            0  ...         furniture\n",
              "1            0  ...  home_improvement\n",
              "2            0  ...              home\n",
              "3            0  ...          wireless\n",
              "4            0  ...                pc\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TRiVTps-QtCM",
        "outputId": "a9048ceb-5689-42ec-c953-16ff47bdef14"
      },
      "source": [
        "print ((df['star_rating'] == 0).sum())\n",
        "print ((df['star_rating'] == 1).sum())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "120000\n",
            "80000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1ijdaHT9QtCM"
      },
      "source": [
        "### divide data and create data splits"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WREgQyOmQtCN",
        "outputId": "a5673f0a-496c-4007-945a-a46fd01c62e1"
      },
      "source": [
        "def train_val_test_split(X, y, val_size, test_size, shuffle):\n",
        "    \"\"\"Split data into train/val/test datasets.\"\"\"\n",
        "    \n",
        "\n",
        "    X_train, X_test, y_train, y_test = train_test_split(\n",
        "        X, y, test_size=test_size, stratify=y, shuffle=shuffle)\n",
        "    \n",
        "    X_train, X_val, y_train, y_val = train_test_split(\n",
        "        X_train, y_train, test_size=val_size, stratify=y_train, shuffle=shuffle)\n",
        "   \n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "\n",
        "TRAIN_SIZE = 0.7\n",
        "VAL_SIZE = 0.15\n",
        "TEST_SIZE = 0.15\n",
        "SHUFFLE = True\n",
        "\n",
        "# Create data splits\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = train_val_test_split(\n",
        "    X=X, y=y, val_size=VAL_SIZE, test_size=TEST_SIZE, shuffle=SHUFFLE)\n",
        "class_counts = dict(collections.Counter(y))\n",
        "print (f\"X_train: {X_train.shape}, y_train: {y_train.shape}\")\n",
        "print (f\"X_val: {X_val.shape}, y_val: {y_val.shape}\")\n",
        "print (f\"X_test: {X_test.shape}, y_test: {y_test.shape}\")\n",
        "print (f\"Sample point: {X_train[1]} â†’ {y_train[1]}\")\n",
        "print (f\"Classes: {class_counts}\")\n",
        "\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X_train: (144500,), y_train: (144500,)\n",
            "X_val: (25500,), y_val: (25500,)\n",
            "X_test: (30000,), y_test: (30000,)\n",
            "Sample point: I wanted in black color â†’ 0\n",
            "Classes: {0: 120000, 1: 80000}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VRZ9M1_4QtCN",
        "outputId": "79388fa8-606d-41d0-9b66-b4af65e355c3"
      },
      "source": [
        "y_train[1]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fBekU5BbQtCO"
      },
      "source": [
        "## tokenization and input formatting for bert"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159,
          "referenced_widgets": [
            "8e8f9c61770c421f99caf888151d7709",
            "2324fd6dbb484e6bbac2aaf21195cd7d",
            "26bf23e62c2e4e29b52d98763942093c",
            "90db4328999a42bfb2142e3ef6ef3fcf",
            "5a2dcab29d134b3ca840a445ba8e758b",
            "5769c72b3cc44553861d42ae37e434dc",
            "7dfca9ed4b3547ecbb85de5f8e9c9577",
            "c1677052ec8340fdadd420dbd3bff3b1"
          ]
        },
        "id": "tOBPYXslQtCO",
        "outputId": "630c03c3-9402-40cb-a7cb-2ed5ed4b929d"
      },
      "source": [
        "from transformers import BertTokenizer\n",
        "\n",
        "# Load the BERT tokenizer.\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8e8f9c61770c421f99caf888151d7709",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1VyZ6eCAQtCP",
        "outputId": "f35f9826-a979-4353-e8c1-1452ee366967"
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreTrainedTokenizer(name_or_path='bert-base-uncased', vocab_size=30522, model_max_len=512, is_fast=False, padding_side='right', special_tokens={'unk_token': '[UNK]', 'sep_token': '[SEP]', 'pad_token': '[PAD]', 'cls_token': '[CLS]', 'mask_token': '[MASK]'})"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjQJAXsyQtCP",
        "outputId": "f094fc98-8586-4a35-b97c-3b11ff7c2a49"
      },
      "source": [
        "## para probar \n",
        "print(\"original: \", X[1])\n",
        "print(\"tokenized\", tokenizer.tokenize(X[1]))\n",
        "print('Token IDs: ', tokenizer.convert_tokens_to_ids(tokenizer.tokenize(X[1])))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "original:  the cabinet dot were all detached from backing... got me\n",
            "tokenized ['the', 'cabinet', 'dot', 'were', 'all', 'detached', 'from', 'backing', '.', '.', '.', 'got', 'me']\n",
            "Token IDs:  [1996, 5239, 11089, 2020, 2035, 12230, 2013, 5150, 1012, 1012, 1012, 2288, 2033]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0cpmz0GQtCQ"
      },
      "source": [
        "tenemos que aÃ±adir tokens especiales para que los entienda BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOeI5tdVQtCQ",
        "outputId": "9a016e19-25cd-43ec-aaea-6c64564a3ae6"
      },
      "source": [
        "%%capture\n",
        "input_ids = []\n",
        "\n",
        "for rev in X_train:\n",
        "    enconde_rev = tokenizer.encode(rev,add_special_tokens = True)\n",
        "    input_ids.append(enconde_rev)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Token indices sequence length is longer than the specified maximum sequence length for this model (550 > 512). Running this sequence through the model will result in indexing errors\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lunuExjQQtCR"
      },
      "source": [
        "%%capture\n",
        "input_ids_test = []\n",
        "\n",
        "for rev in X_test:\n",
        "    enconde_rev = tokenizer.encode(rev,add_special_tokens = True)\n",
        "    input_ids_test.append(enconde_rev)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP2AJO2RQtCR"
      },
      "source": [
        "#tokenizer.encode??"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyxziPRqQtCR",
        "outputId": "0dfe0386-b780-4ab0-b3fb-cca7d7160e9a"
      },
      "source": [
        "print('Original: ', X_train[1])\n",
        "print('Token IDs:', input_ids[1])"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  I wanted in black color\n",
            "Token IDs: [101, 1045, 2359, 1999, 2304, 3609, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiVe7VGVQtCS",
        "outputId": "b8dd1311-13f5-45ef-f148-663fe1625922"
      },
      "source": [
        "print('Original: ', X_test[1])\n",
        "print('Token IDs:', input_ids_test[1])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Arrived 11 days after I ordered. Arrived as one big chunk of chocolate. Looks like it completely melted and then cooled and hardened. What a waste.\n",
            "Token IDs: [101, 3369, 2340, 2420, 2044, 1045, 3641, 1012, 3369, 2004, 2028, 2502, 20000, 1997, 7967, 1012, 3504, 2066, 2009, 3294, 12501, 1998, 2059, 12981, 1998, 15015, 1012, 2054, 1037, 5949, 1012, 102]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvbO1bdbQtCS"
      },
      "source": [
        "## padding and truncating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ue9rgqMfQtCS",
        "outputId": "6c0458d7-606d-4fcf-d1fa-1604c19f6dee"
      },
      "source": [
        "print('Max review length: ', max([len(rev) for sen in input_ids]))\n",
        "print('Max review length: ', max([len(rev) for sen in input_ids_test]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Max review length:  311\n",
            "Max review length:  311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtoqnIGxQtCT"
      },
      "source": [
        "%%capture\n",
        "!pip install tensorflow\n",
        "!pip install Keras\n",
        "import tensorflow as tf\n",
        "import tensorflow \n",
        "\n",
        "from tensorflow import keras\n",
        "\n",
        "from keras.layers import Dense\n",
        "\n",
        "from keras.preprocessing.sequence import pad_sequences\n"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_2lckmCoQtCT",
        "outputId": "a8f21431-4692-4957-b95d-1d594376da21"
      },
      "source": [
        "MAX_LEN = 256\n",
        "\n",
        "print('\\nPadding/truncating all sentences to %d values...' % MAX_LEN)\n",
        "print('\\nPadding token: \"{:}\", ID: {:}'.format(tokenizer.pad_token, tokenizer.pad_token_id))\n",
        "\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "input_ids_test = pad_sequences(input_ids_test, maxlen=MAX_LEN, dtype=\"long\", \n",
        "                          value=0, truncating=\"post\", padding=\"post\")\n",
        "\n",
        "\n",
        "print('\\nDone.')"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Padding/truncating all sentences to 256 values...\n",
            "\n",
            "Padding token: \"[PAD]\", ID: 0\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYKtni5RQtCT"
      },
      "source": [
        "## attention masks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VP58tKTKQtCT"
      },
      "source": [
        "define que tokens son palabras reales y las distingue del padding,\n",
        "el vocab de bert no usa ID 0 entonces si el ID es 0 es padding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2Ja2QQAQtCU"
      },
      "source": [
        "att_masks = []\n",
        "\n",
        "att_masks_test = []\n",
        "\n",
        "for review in input_ids:\n",
        "    attention_mask = [int(token_id > 0) for token_id in review]\n",
        "    att_masks.append(attention_mask)\n",
        "    \n",
        "for review in input_ids_test:\n",
        "    attention_mask = [int(token_id > 0) for token_id in review]\n",
        "    att_masks_test.append(attention_mask)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O8K9befXQtCU"
      },
      "source": [
        "## convert to pytorch datatypes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3hYCjWdQtCU"
      },
      "source": [
        "input_ids = torch.tensor(input_ids)\n",
        "input_ids_test = torch.tensor(input_ids_test)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WvENtGUQtCU"
      },
      "source": [
        "y_train= torch.tensor(y_train)\n",
        "y_test = torch.tensor(y_test)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP1Wo_tfQtCU"
      },
      "source": [
        "att_masks = torch.tensor(att_masks)\n",
        "att_masks_test = torch.tensor(att_masks_test)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hMGJv6VQtCV"
      },
      "source": [
        "## creamos DataLoaders"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds1M6fsbQtCV"
      },
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deaa_ZF7QtCX"
      },
      "source": [
        "batch_size = 32 # recomendado\n",
        "\n",
        "# DATALOADER para el train data\n",
        "train_data = TensorDataset(input_ids,att_masks,y_train)\n",
        "train_sampler= RandomSampler(train_data)\n",
        "train_dataloader= DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-WNEGt7QtCY"
      },
      "source": [
        "#DATALOADER para el test data\n",
        "test_data = TensorDataset(input_ids_test,att_masks_test,y_test)\n",
        "test_sampler= RandomSampler(test_data)\n",
        "test_dataloader= DataLoader(test_data,sampler=test_sampler,batch_size=batch_size)\n",
        "\n",
        "\n"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PICZxMHzQtCZ"
      },
      "source": [
        "# Train el Modelo de Clasificacion "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aq7fVSGQtCZ"
      },
      "source": [
        "## BertForSequenceClassification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecZKy5ZUQtCZ"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "07fa3ac342244e669ae1bb2e9d5fb1a3",
            "673502a40074410291fe85c11c138d1b",
            "d0c6c33e034d43d4a8a2e99d16d100bd",
            "2ac65446b8484166b7004678416453de",
            "4db59796c27c4d73ae584a04cee3c98e",
            "5630810522334199b1ee9e0c913fa4f9",
            "e93859e25f1548e8aa64a7b0d55614f1",
            "42dc53270f324ddba91a19dc0a89683b",
            "07477a4449414f3bb867d24e88f38de3",
            "850ba750be4d4ce88013b94b705b1401",
            "df4340a5de7e4863a08e1b61836cb52b",
            "952f139896f9451eb7a1c21a7b5b2ddd",
            "2ccfd1a533374af185713666915094ee",
            "6f50df78629243c9a2056d5768a60b0c",
            "d85f122dee7240a28f5151c2b5a19499",
            "138ff7843bef474a8c6844e95be9c574"
          ]
        },
        "id": "lzHrvOPfQtCZ",
        "outputId": "ff3107f5-0e52-4ab5-cebd-5db198d2bc04"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                        num_labels= 2,\n",
        "                                                        output_attentions = False,\n",
        "                                                        output_hidden_states= False)\n",
        "model.cuda()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07fa3ac342244e669ae1bb2e9d5fb1a3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07477a4449414f3bb867d24e88f38de3",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZNmDpxLZQtCZ",
        "outputId": "49f0798d-2883-42b1-b209-3fa403c0e026"
      },
      "source": [
        " ##Â ponemos todos los parametros como lista\n",
        "    \n",
        "params = list(model.named_parameters())\n",
        "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
        "\n",
        "print('==== Embedding Layer ====\\n')\n",
        "\n",
        "for p in params[0:5]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== First Transformer ====\\n')\n",
        "\n",
        "for p in params[5:21]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
        "\n",
        "print('\\n==== Output Layer ====\\n')\n",
        "\n",
        "for p in params[-4:]:\n",
        "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The BERT model has 201 different named parameters.\n",
            "\n",
            "==== Embedding Layer ====\n",
            "\n",
            "bert.embeddings.word_embeddings.weight                  (30522, 768)\n",
            "bert.embeddings.position_embeddings.weight                (512, 768)\n",
            "bert.embeddings.token_type_embeddings.weight                (2, 768)\n",
            "bert.embeddings.LayerNorm.weight                              (768,)\n",
            "bert.embeddings.LayerNorm.bias                                (768,)\n",
            "\n",
            "==== First Transformer ====\n",
            "\n",
            "bert.encoder.layer.0.attention.self.query.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.query.bias                (768,)\n",
            "bert.encoder.layer.0.attention.self.key.weight            (768, 768)\n",
            "bert.encoder.layer.0.attention.self.key.bias                  (768,)\n",
            "bert.encoder.layer.0.attention.self.value.weight          (768, 768)\n",
            "bert.encoder.layer.0.attention.self.value.bias                (768,)\n",
            "bert.encoder.layer.0.attention.output.dense.weight        (768, 768)\n",
            "bert.encoder.layer.0.attention.output.dense.bias              (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.weight        (768,)\n",
            "bert.encoder.layer.0.attention.output.LayerNorm.bias          (768,)\n",
            "bert.encoder.layer.0.intermediate.dense.weight           (3072, 768)\n",
            "bert.encoder.layer.0.intermediate.dense.bias                 (3072,)\n",
            "bert.encoder.layer.0.output.dense.weight                 (768, 3072)\n",
            "bert.encoder.layer.0.output.dense.bias                        (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.weight                  (768,)\n",
            "bert.encoder.layer.0.output.LayerNorm.bias                    (768,)\n",
            "\n",
            "==== Output Layer ====\n",
            "\n",
            "bert.pooler.dense.weight                                  (768, 768)\n",
            "bert.pooler.dense.bias                                        (768,)\n",
            "classifier.weight                                           (2, 768)\n",
            "classifier.bias                                                 (2,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bUQRg6mQtCa"
      },
      "source": [
        "## optimizer y leaning rate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiLGD-WLQtCa"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),lr = 2e-5,eps= 1e-8)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vkBGhPE0QtCb",
        "outputId": "15236bc2-bccd-493c-fe4f-bd619ec13b5c"
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "## de la documentacion :\n",
        "\n",
        "#Create a schedule with a constant learning rate \n",
        "#preceded by a warmup period during which the learning rate \n",
        "#increases linearly between 0 and the initial lr set \n",
        "#in the optimizer.\n",
        "\n",
        "epochs= 4\n",
        "total_steps= len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer,num_warmup_steps = 0, num_training_steps = total_steps)\n",
        "scheduler"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.optim.lr_scheduler.LambdaLR at 0x7f75db95ecc0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jsZeU6SrQtCb"
      },
      "source": [
        "## training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AoHKrQpQtCc"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Funcion para calcular la accuracy (pred-labels)\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbs7tjCiQtCc"
      },
      "source": [
        "## para medir los tiempos\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yr9kqJJZQtCc"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8pxJWrblQtCc",
        "outputId": "ed83ea6e-d57f-426f-f6d1-035eda0cb144"
      },
      "source": [
        "import random\n",
        "\n",
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "# Guarda las perdidas (Average) despuÃ©s de cada epoch para poder plotear despues\n",
        "loss_values = []\n",
        "\n",
        "# para cada epoch:\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    \n",
        "    #Training\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}.'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        # Always clear any previously calculated gradients before performing a backward pass.\n",
        "        model.zero_grad()        \n",
        "\n",
        "    \n",
        "        outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        # Clip the norm of the gradients to 1.0.\n",
        "        # This is to help prevent the \"exploding gradients\" problem.\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over the training data.\n",
        "    avg_train_loss = total_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Store the loss value for plotting the learning curve.\n",
        "    loss_values.append(avg_train_loss)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
        "  \n",
        "\n",
        "\n",
        "    ## Validation\n",
        "   \n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in test_dataloader:\n",
        "        \n",
        "        # Add batch to GPU\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        \n",
        "        # Unpack the inputs from our dataloader\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "        \n",
        "        logits = outputs[0]\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        \n",
        "        # Calculate the accuracy for this batch of test sentences.\n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        \n",
        "        # Accumulate the total accuracy.\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "\n",
        "        # Track the number of batches\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    print(\"  Accuracy: {0:.2f}\".format(eval_accuracy/nb_eval_steps))\n",
        "    print(\"  Validation took: {:}\".format(format_time(time.time() - t0)))\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "   "
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,516.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  4,516.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  4,516.    Elapsed: 0:01:33.\n",
            "  Batch   160  of  4,516.    Elapsed: 0:02:03.\n",
            "  Batch   200  of  4,516.    Elapsed: 0:02:34.\n",
            "  Batch   240  of  4,516.    Elapsed: 0:03:05.\n",
            "  Batch   280  of  4,516.    Elapsed: 0:03:36.\n",
            "  Batch   320  of  4,516.    Elapsed: 0:04:06.\n",
            "  Batch   360  of  4,516.    Elapsed: 0:04:37.\n",
            "  Batch   400  of  4,516.    Elapsed: 0:05:08.\n",
            "  Batch   440  of  4,516.    Elapsed: 0:05:39.\n",
            "  Batch   480  of  4,516.    Elapsed: 0:06:09.\n",
            "  Batch   520  of  4,516.    Elapsed: 0:06:40.\n",
            "  Batch   560  of  4,516.    Elapsed: 0:07:11.\n",
            "  Batch   600  of  4,516.    Elapsed: 0:07:42.\n",
            "  Batch   640  of  4,516.    Elapsed: 0:08:12.\n",
            "  Batch   680  of  4,516.    Elapsed: 0:08:43.\n",
            "  Batch   720  of  4,516.    Elapsed: 0:09:14.\n",
            "  Batch   760  of  4,516.    Elapsed: 0:09:45.\n",
            "  Batch   800  of  4,516.    Elapsed: 0:10:16.\n",
            "  Batch   840  of  4,516.    Elapsed: 0:10:46.\n",
            "  Batch   880  of  4,516.    Elapsed: 0:11:17.\n",
            "  Batch   920  of  4,516.    Elapsed: 0:11:48.\n",
            "  Batch   960  of  4,516.    Elapsed: 0:12:19.\n",
            "  Batch 1,000  of  4,516.    Elapsed: 0:12:49.\n",
            "  Batch 1,040  of  4,516.    Elapsed: 0:13:20.\n",
            "  Batch 1,080  of  4,516.    Elapsed: 0:13:51.\n",
            "  Batch 1,120  of  4,516.    Elapsed: 0:14:22.\n",
            "  Batch 1,160  of  4,516.    Elapsed: 0:14:52.\n",
            "  Batch 1,200  of  4,516.    Elapsed: 0:15:23.\n",
            "  Batch 1,240  of  4,516.    Elapsed: 0:15:54.\n",
            "  Batch 1,280  of  4,516.    Elapsed: 0:16:25.\n",
            "  Batch 1,320  of  4,516.    Elapsed: 0:16:56.\n",
            "  Batch 1,360  of  4,516.    Elapsed: 0:17:26.\n",
            "  Batch 1,400  of  4,516.    Elapsed: 0:17:57.\n",
            "  Batch 1,440  of  4,516.    Elapsed: 0:18:28.\n",
            "  Batch 1,480  of  4,516.    Elapsed: 0:18:59.\n",
            "  Batch 1,520  of  4,516.    Elapsed: 0:19:30.\n",
            "  Batch 1,560  of  4,516.    Elapsed: 0:20:00.\n",
            "  Batch 1,600  of  4,516.    Elapsed: 0:20:31.\n",
            "  Batch 1,640  of  4,516.    Elapsed: 0:21:02.\n",
            "  Batch 1,680  of  4,516.    Elapsed: 0:21:33.\n",
            "  Batch 1,720  of  4,516.    Elapsed: 0:22:04.\n",
            "  Batch 1,760  of  4,516.    Elapsed: 0:22:34.\n",
            "  Batch 1,800  of  4,516.    Elapsed: 0:23:05.\n",
            "  Batch 1,840  of  4,516.    Elapsed: 0:23:36.\n",
            "  Batch 1,880  of  4,516.    Elapsed: 0:24:07.\n",
            "  Batch 1,920  of  4,516.    Elapsed: 0:24:38.\n",
            "  Batch 1,960  of  4,516.    Elapsed: 0:25:08.\n",
            "  Batch 2,000  of  4,516.    Elapsed: 0:25:39.\n",
            "  Batch 2,040  of  4,516.    Elapsed: 0:26:10.\n",
            "  Batch 2,080  of  4,516.    Elapsed: 0:26:41.\n",
            "  Batch 2,120  of  4,516.    Elapsed: 0:27:12.\n",
            "  Batch 2,160  of  4,516.    Elapsed: 0:27:42.\n",
            "  Batch 2,200  of  4,516.    Elapsed: 0:28:13.\n",
            "  Batch 2,240  of  4,516.    Elapsed: 0:28:44.\n",
            "  Batch 2,280  of  4,516.    Elapsed: 0:29:15.\n",
            "  Batch 2,320  of  4,516.    Elapsed: 0:29:46.\n",
            "  Batch 2,360  of  4,516.    Elapsed: 0:30:16.\n",
            "  Batch 2,400  of  4,516.    Elapsed: 0:30:47.\n",
            "  Batch 2,440  of  4,516.    Elapsed: 0:31:18.\n",
            "  Batch 2,480  of  4,516.    Elapsed: 0:31:49.\n",
            "  Batch 2,520  of  4,516.    Elapsed: 0:32:20.\n",
            "  Batch 2,560  of  4,516.    Elapsed: 0:32:51.\n",
            "  Batch 2,600  of  4,516.    Elapsed: 0:33:21.\n",
            "  Batch 2,640  of  4,516.    Elapsed: 0:33:52.\n",
            "  Batch 2,680  of  4,516.    Elapsed: 0:34:23.\n",
            "  Batch 2,720  of  4,516.    Elapsed: 0:34:54.\n",
            "  Batch 2,760  of  4,516.    Elapsed: 0:35:25.\n",
            "  Batch 2,800  of  4,516.    Elapsed: 0:35:55.\n",
            "  Batch 2,840  of  4,516.    Elapsed: 0:36:26.\n",
            "  Batch 2,880  of  4,516.    Elapsed: 0:36:57.\n",
            "  Batch 2,920  of  4,516.    Elapsed: 0:37:28.\n",
            "  Batch 2,960  of  4,516.    Elapsed: 0:37:59.\n",
            "  Batch 3,000  of  4,516.    Elapsed: 0:38:29.\n",
            "  Batch 3,040  of  4,516.    Elapsed: 0:39:00.\n",
            "  Batch 3,080  of  4,516.    Elapsed: 0:39:31.\n",
            "  Batch 3,120  of  4,516.    Elapsed: 0:40:02.\n",
            "  Batch 3,160  of  4,516.    Elapsed: 0:40:33.\n",
            "  Batch 3,200  of  4,516.    Elapsed: 0:41:03.\n",
            "  Batch 3,240  of  4,516.    Elapsed: 0:41:34.\n",
            "  Batch 3,280  of  4,516.    Elapsed: 0:42:05.\n",
            "  Batch 3,320  of  4,516.    Elapsed: 0:42:36.\n",
            "  Batch 3,360  of  4,516.    Elapsed: 0:43:07.\n",
            "  Batch 3,400  of  4,516.    Elapsed: 0:43:38.\n",
            "  Batch 3,440  of  4,516.    Elapsed: 0:44:08.\n",
            "  Batch 3,480  of  4,516.    Elapsed: 0:44:39.\n",
            "  Batch 3,520  of  4,516.    Elapsed: 0:45:10.\n",
            "  Batch 3,560  of  4,516.    Elapsed: 0:45:41.\n",
            "  Batch 3,600  of  4,516.    Elapsed: 0:46:11.\n",
            "  Batch 3,640  of  4,516.    Elapsed: 0:46:42.\n",
            "  Batch 3,680  of  4,516.    Elapsed: 0:47:13.\n",
            "  Batch 3,720  of  4,516.    Elapsed: 0:47:44.\n",
            "  Batch 3,760  of  4,516.    Elapsed: 0:48:15.\n",
            "  Batch 3,800  of  4,516.    Elapsed: 0:48:45.\n",
            "  Batch 3,840  of  4,516.    Elapsed: 0:49:16.\n",
            "  Batch 3,880  of  4,516.    Elapsed: 0:49:47.\n",
            "  Batch 3,920  of  4,516.    Elapsed: 0:50:18.\n",
            "  Batch 3,960  of  4,516.    Elapsed: 0:50:49.\n",
            "  Batch 4,000  of  4,516.    Elapsed: 0:51:20.\n",
            "  Batch 4,040  of  4,516.    Elapsed: 0:51:50.\n",
            "  Batch 4,080  of  4,516.    Elapsed: 0:52:21.\n",
            "  Batch 4,120  of  4,516.    Elapsed: 0:52:52.\n",
            "  Batch 4,160  of  4,516.    Elapsed: 0:53:23.\n",
            "  Batch 4,200  of  4,516.    Elapsed: 0:53:54.\n",
            "  Batch 4,240  of  4,516.    Elapsed: 0:54:24.\n",
            "  Batch 4,280  of  4,516.    Elapsed: 0:54:55.\n",
            "  Batch 4,320  of  4,516.    Elapsed: 0:55:26.\n",
            "  Batch 4,360  of  4,516.    Elapsed: 0:55:57.\n",
            "  Batch 4,400  of  4,516.    Elapsed: 0:56:28.\n",
            "  Batch 4,440  of  4,516.    Elapsed: 0:56:59.\n",
            "  Batch 4,480  of  4,516.    Elapsed: 0:57:29.\n",
            "\n",
            "  Average training loss: 0.27\n",
            "  Training epcoh took: 0:57:57\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:03:57\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,516.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  4,516.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  4,516.    Elapsed: 0:01:33.\n",
            "  Batch   160  of  4,516.    Elapsed: 0:02:03.\n",
            "  Batch   200  of  4,516.    Elapsed: 0:02:34.\n",
            "  Batch   240  of  4,516.    Elapsed: 0:03:05.\n",
            "  Batch   280  of  4,516.    Elapsed: 0:03:36.\n",
            "  Batch   320  of  4,516.    Elapsed: 0:04:07.\n",
            "  Batch   360  of  4,516.    Elapsed: 0:04:37.\n",
            "  Batch   400  of  4,516.    Elapsed: 0:05:08.\n",
            "  Batch   440  of  4,516.    Elapsed: 0:05:39.\n",
            "  Batch   480  of  4,516.    Elapsed: 0:06:10.\n",
            "  Batch   520  of  4,516.    Elapsed: 0:06:41.\n",
            "  Batch   560  of  4,516.    Elapsed: 0:07:12.\n",
            "  Batch   600  of  4,516.    Elapsed: 0:07:42.\n",
            "  Batch   640  of  4,516.    Elapsed: 0:08:13.\n",
            "  Batch   680  of  4,516.    Elapsed: 0:08:44.\n",
            "  Batch   720  of  4,516.    Elapsed: 0:09:15.\n",
            "  Batch   760  of  4,516.    Elapsed: 0:09:46.\n",
            "  Batch   800  of  4,516.    Elapsed: 0:10:17.\n",
            "  Batch   840  of  4,516.    Elapsed: 0:10:47.\n",
            "  Batch   880  of  4,516.    Elapsed: 0:11:18.\n",
            "  Batch   920  of  4,516.    Elapsed: 0:11:49.\n",
            "  Batch   960  of  4,516.    Elapsed: 0:12:20.\n",
            "  Batch 1,000  of  4,516.    Elapsed: 0:12:51.\n",
            "  Batch 1,040  of  4,516.    Elapsed: 0:13:21.\n",
            "  Batch 1,080  of  4,516.    Elapsed: 0:13:52.\n",
            "  Batch 1,120  of  4,516.    Elapsed: 0:14:23.\n",
            "  Batch 1,160  of  4,516.    Elapsed: 0:14:54.\n",
            "  Batch 1,200  of  4,516.    Elapsed: 0:15:25.\n",
            "  Batch 1,240  of  4,516.    Elapsed: 0:15:56.\n",
            "  Batch 1,280  of  4,516.    Elapsed: 0:16:26.\n",
            "  Batch 1,320  of  4,516.    Elapsed: 0:16:57.\n",
            "  Batch 1,360  of  4,516.    Elapsed: 0:17:28.\n",
            "  Batch 1,400  of  4,516.    Elapsed: 0:17:59.\n",
            "  Batch 1,440  of  4,516.    Elapsed: 0:18:30.\n",
            "  Batch 1,480  of  4,516.    Elapsed: 0:19:00.\n",
            "  Batch 1,520  of  4,516.    Elapsed: 0:19:31.\n",
            "  Batch 1,560  of  4,516.    Elapsed: 0:20:02.\n",
            "  Batch 1,600  of  4,516.    Elapsed: 0:20:33.\n",
            "  Batch 1,640  of  4,516.    Elapsed: 0:21:04.\n",
            "  Batch 1,680  of  4,516.    Elapsed: 0:21:34.\n",
            "  Batch 1,720  of  4,516.    Elapsed: 0:22:05.\n",
            "  Batch 1,760  of  4,516.    Elapsed: 0:22:36.\n",
            "  Batch 1,800  of  4,516.    Elapsed: 0:23:07.\n",
            "  Batch 1,840  of  4,516.    Elapsed: 0:23:38.\n",
            "  Batch 1,880  of  4,516.    Elapsed: 0:24:09.\n",
            "  Batch 1,920  of  4,516.    Elapsed: 0:24:39.\n",
            "  Batch 1,960  of  4,516.    Elapsed: 0:25:10.\n",
            "  Batch 2,000  of  4,516.    Elapsed: 0:25:41.\n",
            "  Batch 2,040  of  4,516.    Elapsed: 0:26:12.\n",
            "  Batch 2,080  of  4,516.    Elapsed: 0:26:43.\n",
            "  Batch 2,120  of  4,516.    Elapsed: 0:27:14.\n",
            "  Batch 2,160  of  4,516.    Elapsed: 0:27:44.\n",
            "  Batch 2,200  of  4,516.    Elapsed: 0:28:15.\n",
            "  Batch 2,240  of  4,516.    Elapsed: 0:28:46.\n",
            "  Batch 2,280  of  4,516.    Elapsed: 0:29:17.\n",
            "  Batch 2,320  of  4,516.    Elapsed: 0:29:48.\n",
            "  Batch 2,360  of  4,516.    Elapsed: 0:30:19.\n",
            "  Batch 2,400  of  4,516.    Elapsed: 0:30:49.\n",
            "  Batch 2,440  of  4,516.    Elapsed: 0:31:20.\n",
            "  Batch 2,480  of  4,516.    Elapsed: 0:31:51.\n",
            "  Batch 2,520  of  4,516.    Elapsed: 0:32:22.\n",
            "  Batch 2,560  of  4,516.    Elapsed: 0:32:53.\n",
            "  Batch 2,600  of  4,516.    Elapsed: 0:33:24.\n",
            "  Batch 2,640  of  4,516.    Elapsed: 0:33:54.\n",
            "  Batch 2,680  of  4,516.    Elapsed: 0:34:25.\n",
            "  Batch 2,720  of  4,516.    Elapsed: 0:34:56.\n",
            "  Batch 2,760  of  4,516.    Elapsed: 0:35:27.\n",
            "  Batch 2,800  of  4,516.    Elapsed: 0:35:58.\n",
            "  Batch 2,840  of  4,516.    Elapsed: 0:36:28.\n",
            "  Batch 2,880  of  4,516.    Elapsed: 0:36:59.\n",
            "  Batch 2,920  of  4,516.    Elapsed: 0:37:30.\n",
            "  Batch 2,960  of  4,516.    Elapsed: 0:38:01.\n",
            "  Batch 3,000  of  4,516.    Elapsed: 0:38:32.\n",
            "  Batch 3,040  of  4,516.    Elapsed: 0:39:03.\n",
            "  Batch 3,080  of  4,516.    Elapsed: 0:39:33.\n",
            "  Batch 3,120  of  4,516.    Elapsed: 0:40:04.\n",
            "  Batch 3,160  of  4,516.    Elapsed: 0:40:35.\n",
            "  Batch 3,200  of  4,516.    Elapsed: 0:41:06.\n",
            "  Batch 3,240  of  4,516.    Elapsed: 0:41:37.\n",
            "  Batch 3,280  of  4,516.    Elapsed: 0:42:08.\n",
            "  Batch 3,320  of  4,516.    Elapsed: 0:42:38.\n",
            "  Batch 3,360  of  4,516.    Elapsed: 0:43:09.\n",
            "  Batch 3,400  of  4,516.    Elapsed: 0:43:40.\n",
            "  Batch 3,440  of  4,516.    Elapsed: 0:44:11.\n",
            "  Batch 3,480  of  4,516.    Elapsed: 0:44:42.\n",
            "  Batch 3,520  of  4,516.    Elapsed: 0:45:13.\n",
            "  Batch 3,560  of  4,516.    Elapsed: 0:45:43.\n",
            "  Batch 3,600  of  4,516.    Elapsed: 0:46:14.\n",
            "  Batch 3,640  of  4,516.    Elapsed: 0:46:45.\n",
            "  Batch 3,680  of  4,516.    Elapsed: 0:47:16.\n",
            "  Batch 3,720  of  4,516.    Elapsed: 0:47:47.\n",
            "  Batch 3,760  of  4,516.    Elapsed: 0:48:18.\n",
            "  Batch 3,800  of  4,516.    Elapsed: 0:48:48.\n",
            "  Batch 3,840  of  4,516.    Elapsed: 0:49:19.\n",
            "  Batch 3,880  of  4,516.    Elapsed: 0:49:50.\n",
            "  Batch 3,920  of  4,516.    Elapsed: 0:50:21.\n",
            "  Batch 3,960  of  4,516.    Elapsed: 0:50:52.\n",
            "  Batch 4,000  of  4,516.    Elapsed: 0:51:22.\n",
            "  Batch 4,040  of  4,516.    Elapsed: 0:51:53.\n",
            "  Batch 4,080  of  4,516.    Elapsed: 0:52:24.\n",
            "  Batch 4,120  of  4,516.    Elapsed: 0:52:55.\n",
            "  Batch 4,160  of  4,516.    Elapsed: 0:53:26.\n",
            "  Batch 4,200  of  4,516.    Elapsed: 0:53:56.\n",
            "  Batch 4,240  of  4,516.    Elapsed: 0:54:27.\n",
            "  Batch 4,280  of  4,516.    Elapsed: 0:54:58.\n",
            "  Batch 4,320  of  4,516.    Elapsed: 0:55:29.\n",
            "  Batch 4,360  of  4,516.    Elapsed: 0:56:00.\n",
            "  Batch 4,400  of  4,516.    Elapsed: 0:56:31.\n",
            "  Batch 4,440  of  4,516.    Elapsed: 0:57:01.\n",
            "  Batch 4,480  of  4,516.    Elapsed: 0:57:32.\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:58:00\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:03:57\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,516.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  4,516.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  4,516.    Elapsed: 0:01:32.\n",
            "  Batch   160  of  4,516.    Elapsed: 0:02:03.\n",
            "  Batch   200  of  4,516.    Elapsed: 0:02:34.\n",
            "  Batch   240  of  4,516.    Elapsed: 0:03:05.\n",
            "  Batch   280  of  4,516.    Elapsed: 0:03:36.\n",
            "  Batch   320  of  4,516.    Elapsed: 0:04:06.\n",
            "  Batch   360  of  4,516.    Elapsed: 0:04:37.\n",
            "  Batch   400  of  4,516.    Elapsed: 0:05:08.\n",
            "  Batch   440  of  4,516.    Elapsed: 0:05:39.\n",
            "  Batch   480  of  4,516.    Elapsed: 0:06:10.\n",
            "  Batch   520  of  4,516.    Elapsed: 0:06:40.\n",
            "  Batch   560  of  4,516.    Elapsed: 0:07:11.\n",
            "  Batch   600  of  4,516.    Elapsed: 0:07:42.\n",
            "  Batch   640  of  4,516.    Elapsed: 0:08:13.\n",
            "  Batch   680  of  4,516.    Elapsed: 0:08:44.\n",
            "  Batch   720  of  4,516.    Elapsed: 0:09:15.\n",
            "  Batch   760  of  4,516.    Elapsed: 0:09:45.\n",
            "  Batch   800  of  4,516.    Elapsed: 0:10:16.\n",
            "  Batch   840  of  4,516.    Elapsed: 0:10:47.\n",
            "  Batch   880  of  4,516.    Elapsed: 0:11:18.\n",
            "  Batch   920  of  4,516.    Elapsed: 0:11:49.\n",
            "  Batch   960  of  4,516.    Elapsed: 0:12:19.\n",
            "  Batch 1,000  of  4,516.    Elapsed: 0:12:50.\n",
            "  Batch 1,040  of  4,516.    Elapsed: 0:13:21.\n",
            "  Batch 1,080  of  4,516.    Elapsed: 0:13:52.\n",
            "  Batch 1,120  of  4,516.    Elapsed: 0:14:22.\n",
            "  Batch 1,160  of  4,516.    Elapsed: 0:14:53.\n",
            "  Batch 1,200  of  4,516.    Elapsed: 0:15:24.\n",
            "  Batch 1,240  of  4,516.    Elapsed: 0:15:55.\n",
            "  Batch 1,280  of  4,516.    Elapsed: 0:16:26.\n",
            "  Batch 1,320  of  4,516.    Elapsed: 0:16:57.\n",
            "  Batch 1,360  of  4,516.    Elapsed: 0:17:27.\n",
            "  Batch 1,400  of  4,516.    Elapsed: 0:17:58.\n",
            "  Batch 1,440  of  4,516.    Elapsed: 0:18:29.\n",
            "  Batch 1,480  of  4,516.    Elapsed: 0:19:00.\n",
            "  Batch 1,520  of  4,516.    Elapsed: 0:19:31.\n",
            "  Batch 1,560  of  4,516.    Elapsed: 0:20:01.\n",
            "  Batch 1,600  of  4,516.    Elapsed: 0:20:32.\n",
            "  Batch 1,640  of  4,516.    Elapsed: 0:21:03.\n",
            "  Batch 1,680  of  4,516.    Elapsed: 0:21:34.\n",
            "  Batch 1,720  of  4,516.    Elapsed: 0:22:05.\n",
            "  Batch 1,760  of  4,516.    Elapsed: 0:22:35.\n",
            "  Batch 1,800  of  4,516.    Elapsed: 0:23:06.\n",
            "  Batch 1,840  of  4,516.    Elapsed: 0:23:37.\n",
            "  Batch 1,880  of  4,516.    Elapsed: 0:24:08.\n",
            "  Batch 1,920  of  4,516.    Elapsed: 0:24:39.\n",
            "  Batch 1,960  of  4,516.    Elapsed: 0:25:09.\n",
            "  Batch 2,000  of  4,516.    Elapsed: 0:25:40.\n",
            "  Batch 2,040  of  4,516.    Elapsed: 0:26:11.\n",
            "  Batch 2,080  of  4,516.    Elapsed: 0:26:42.\n",
            "  Batch 2,120  of  4,516.    Elapsed: 0:27:13.\n",
            "  Batch 2,160  of  4,516.    Elapsed: 0:27:43.\n",
            "  Batch 2,200  of  4,516.    Elapsed: 0:28:14.\n",
            "  Batch 2,240  of  4,516.    Elapsed: 0:28:45.\n",
            "  Batch 2,280  of  4,516.    Elapsed: 0:29:16.\n",
            "  Batch 2,320  of  4,516.    Elapsed: 0:29:47.\n",
            "  Batch 2,360  of  4,516.    Elapsed: 0:30:18.\n",
            "  Batch 2,400  of  4,516.    Elapsed: 0:30:48.\n",
            "  Batch 2,440  of  4,516.    Elapsed: 0:31:19.\n",
            "  Batch 2,480  of  4,516.    Elapsed: 0:31:50.\n",
            "  Batch 2,520  of  4,516.    Elapsed: 0:32:21.\n",
            "  Batch 2,560  of  4,516.    Elapsed: 0:32:51.\n",
            "  Batch 2,600  of  4,516.    Elapsed: 0:33:22.\n",
            "  Batch 2,640  of  4,516.    Elapsed: 0:33:53.\n",
            "  Batch 2,680  of  4,516.    Elapsed: 0:34:24.\n",
            "  Batch 2,720  of  4,516.    Elapsed: 0:34:55.\n",
            "  Batch 2,760  of  4,516.    Elapsed: 0:35:25.\n",
            "  Batch 2,800  of  4,516.    Elapsed: 0:35:56.\n",
            "  Batch 2,840  of  4,516.    Elapsed: 0:36:27.\n",
            "  Batch 2,880  of  4,516.    Elapsed: 0:36:58.\n",
            "  Batch 2,920  of  4,516.    Elapsed: 0:37:29.\n",
            "  Batch 2,960  of  4,516.    Elapsed: 0:37:59.\n",
            "  Batch 3,000  of  4,516.    Elapsed: 0:38:30.\n",
            "  Batch 3,040  of  4,516.    Elapsed: 0:39:01.\n",
            "  Batch 3,080  of  4,516.    Elapsed: 0:39:32.\n",
            "  Batch 3,120  of  4,516.    Elapsed: 0:40:03.\n",
            "  Batch 3,160  of  4,516.    Elapsed: 0:40:33.\n",
            "  Batch 3,200  of  4,516.    Elapsed: 0:41:04.\n",
            "  Batch 3,240  of  4,516.    Elapsed: 0:41:35.\n",
            "  Batch 3,280  of  4,516.    Elapsed: 0:42:06.\n",
            "  Batch 3,320  of  4,516.    Elapsed: 0:42:37.\n",
            "  Batch 3,360  of  4,516.    Elapsed: 0:43:07.\n",
            "  Batch 3,400  of  4,516.    Elapsed: 0:43:38.\n",
            "  Batch 3,440  of  4,516.    Elapsed: 0:44:09.\n",
            "  Batch 3,480  of  4,516.    Elapsed: 0:44:40.\n",
            "  Batch 3,520  of  4,516.    Elapsed: 0:45:11.\n",
            "  Batch 3,560  of  4,516.    Elapsed: 0:45:42.\n",
            "  Batch 3,600  of  4,516.    Elapsed: 0:46:12.\n",
            "  Batch 3,640  of  4,516.    Elapsed: 0:46:43.\n",
            "  Batch 3,680  of  4,516.    Elapsed: 0:47:14.\n",
            "  Batch 3,720  of  4,516.    Elapsed: 0:47:45.\n",
            "  Batch 3,760  of  4,516.    Elapsed: 0:48:16.\n",
            "  Batch 3,800  of  4,516.    Elapsed: 0:48:47.\n",
            "  Batch 3,840  of  4,516.    Elapsed: 0:49:17.\n",
            "  Batch 3,880  of  4,516.    Elapsed: 0:49:48.\n",
            "  Batch 3,920  of  4,516.    Elapsed: 0:50:19.\n",
            "  Batch 3,960  of  4,516.    Elapsed: 0:50:50.\n",
            "  Batch 4,000  of  4,516.    Elapsed: 0:51:21.\n",
            "  Batch 4,040  of  4,516.    Elapsed: 0:51:51.\n",
            "  Batch 4,080  of  4,516.    Elapsed: 0:52:22.\n",
            "  Batch 4,120  of  4,516.    Elapsed: 0:52:53.\n",
            "  Batch 4,160  of  4,516.    Elapsed: 0:53:24.\n",
            "  Batch 4,200  of  4,516.    Elapsed: 0:53:55.\n",
            "  Batch 4,240  of  4,516.    Elapsed: 0:54:26.\n",
            "  Batch 4,280  of  4,516.    Elapsed: 0:54:56.\n",
            "  Batch 4,320  of  4,516.    Elapsed: 0:55:27.\n",
            "  Batch 4,360  of  4,516.    Elapsed: 0:55:58.\n",
            "  Batch 4,400  of  4,516.    Elapsed: 0:56:29.\n",
            "  Batch 4,440  of  4,516.    Elapsed: 0:57:00.\n",
            "  Batch 4,480  of  4,516.    Elapsed: 0:57:31.\n",
            "\n",
            "  Average training loss: 0.15\n",
            "  Training epcoh took: 0:57:58\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:03:57\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch    40  of  4,516.    Elapsed: 0:00:31.\n",
            "  Batch    80  of  4,516.    Elapsed: 0:01:02.\n",
            "  Batch   120  of  4,516.    Elapsed: 0:01:33.\n",
            "  Batch   160  of  4,516.    Elapsed: 0:02:03.\n",
            "  Batch   200  of  4,516.    Elapsed: 0:02:34.\n",
            "  Batch   240  of  4,516.    Elapsed: 0:03:05.\n",
            "  Batch   280  of  4,516.    Elapsed: 0:03:36.\n",
            "  Batch   320  of  4,516.    Elapsed: 0:04:06.\n",
            "  Batch   360  of  4,516.    Elapsed: 0:04:37.\n",
            "  Batch   400  of  4,516.    Elapsed: 0:05:08.\n",
            "  Batch   440  of  4,516.    Elapsed: 0:05:39.\n",
            "  Batch   480  of  4,516.    Elapsed: 0:06:10.\n",
            "  Batch   520  of  4,516.    Elapsed: 0:06:41.\n",
            "  Batch   560  of  4,516.    Elapsed: 0:07:11.\n",
            "  Batch   600  of  4,516.    Elapsed: 0:07:42.\n",
            "  Batch   640  of  4,516.    Elapsed: 0:08:13.\n",
            "  Batch   680  of  4,516.    Elapsed: 0:08:44.\n",
            "  Batch   720  of  4,516.    Elapsed: 0:09:14.\n",
            "  Batch   760  of  4,516.    Elapsed: 0:09:45.\n",
            "  Batch   800  of  4,516.    Elapsed: 0:10:16.\n",
            "  Batch   840  of  4,516.    Elapsed: 0:10:47.\n",
            "  Batch   880  of  4,516.    Elapsed: 0:11:18.\n",
            "  Batch   920  of  4,516.    Elapsed: 0:11:48.\n",
            "  Batch   960  of  4,516.    Elapsed: 0:12:19.\n",
            "  Batch 1,000  of  4,516.    Elapsed: 0:12:50.\n",
            "  Batch 1,040  of  4,516.    Elapsed: 0:13:21.\n",
            "  Batch 1,080  of  4,516.    Elapsed: 0:13:52.\n",
            "  Batch 1,120  of  4,516.    Elapsed: 0:14:22.\n",
            "  Batch 1,160  of  4,516.    Elapsed: 0:14:53.\n",
            "  Batch 1,200  of  4,516.    Elapsed: 0:15:24.\n",
            "  Batch 1,240  of  4,516.    Elapsed: 0:15:55.\n",
            "  Batch 1,280  of  4,516.    Elapsed: 0:16:26.\n",
            "  Batch 1,320  of  4,516.    Elapsed: 0:16:56.\n",
            "  Batch 1,360  of  4,516.    Elapsed: 0:17:27.\n",
            "  Batch 1,400  of  4,516.    Elapsed: 0:17:58.\n",
            "  Batch 1,440  of  4,516.    Elapsed: 0:18:29.\n",
            "  Batch 1,480  of  4,516.    Elapsed: 0:19:00.\n",
            "  Batch 1,520  of  4,516.    Elapsed: 0:19:30.\n",
            "  Batch 1,560  of  4,516.    Elapsed: 0:20:01.\n",
            "  Batch 1,600  of  4,516.    Elapsed: 0:20:32.\n",
            "  Batch 1,640  of  4,516.    Elapsed: 0:21:03.\n",
            "  Batch 1,680  of  4,516.    Elapsed: 0:21:34.\n",
            "  Batch 1,720  of  4,516.    Elapsed: 0:22:04.\n",
            "  Batch 1,760  of  4,516.    Elapsed: 0:22:35.\n",
            "  Batch 1,800  of  4,516.    Elapsed: 0:23:06.\n",
            "  Batch 1,840  of  4,516.    Elapsed: 0:23:37.\n",
            "  Batch 1,880  of  4,516.    Elapsed: 0:24:07.\n",
            "  Batch 1,920  of  4,516.    Elapsed: 0:24:38.\n",
            "  Batch 1,960  of  4,516.    Elapsed: 0:25:09.\n",
            "  Batch 2,000  of  4,516.    Elapsed: 0:25:40.\n",
            "  Batch 2,040  of  4,516.    Elapsed: 0:26:11.\n",
            "  Batch 2,080  of  4,516.    Elapsed: 0:26:41.\n",
            "  Batch 2,120  of  4,516.    Elapsed: 0:27:12.\n",
            "  Batch 2,160  of  4,516.    Elapsed: 0:27:43.\n",
            "  Batch 2,200  of  4,516.    Elapsed: 0:28:14.\n",
            "  Batch 2,240  of  4,516.    Elapsed: 0:28:45.\n",
            "  Batch 2,280  of  4,516.    Elapsed: 0:29:15.\n",
            "  Batch 2,320  of  4,516.    Elapsed: 0:29:46.\n",
            "  Batch 2,360  of  4,516.    Elapsed: 0:30:17.\n",
            "  Batch 2,400  of  4,516.    Elapsed: 0:30:48.\n",
            "  Batch 2,440  of  4,516.    Elapsed: 0:31:19.\n",
            "  Batch 2,480  of  4,516.    Elapsed: 0:31:49.\n",
            "  Batch 2,520  of  4,516.    Elapsed: 0:32:20.\n",
            "  Batch 2,560  of  4,516.    Elapsed: 0:32:51.\n",
            "  Batch 2,600  of  4,516.    Elapsed: 0:33:22.\n",
            "  Batch 2,640  of  4,516.    Elapsed: 0:33:53.\n",
            "  Batch 2,680  of  4,516.    Elapsed: 0:34:23.\n",
            "  Batch 2,720  of  4,516.    Elapsed: 0:34:54.\n",
            "  Batch 2,760  of  4,516.    Elapsed: 0:35:25.\n",
            "  Batch 2,800  of  4,516.    Elapsed: 0:35:56.\n",
            "  Batch 2,840  of  4,516.    Elapsed: 0:36:27.\n",
            "  Batch 2,880  of  4,516.    Elapsed: 0:36:57.\n",
            "  Batch 2,920  of  4,516.    Elapsed: 0:37:28.\n",
            "  Batch 2,960  of  4,516.    Elapsed: 0:37:59.\n",
            "  Batch 3,000  of  4,516.    Elapsed: 0:38:30.\n",
            "  Batch 3,040  of  4,516.    Elapsed: 0:39:00.\n",
            "  Batch 3,080  of  4,516.    Elapsed: 0:39:31.\n",
            "  Batch 3,120  of  4,516.    Elapsed: 0:40:02.\n",
            "  Batch 3,160  of  4,516.    Elapsed: 0:40:33.\n",
            "  Batch 3,200  of  4,516.    Elapsed: 0:41:04.\n",
            "  Batch 3,240  of  4,516.    Elapsed: 0:41:34.\n",
            "  Batch 3,280  of  4,516.    Elapsed: 0:42:05.\n",
            "  Batch 3,320  of  4,516.    Elapsed: 0:42:36.\n",
            "  Batch 3,360  of  4,516.    Elapsed: 0:43:07.\n",
            "  Batch 3,400  of  4,516.    Elapsed: 0:43:37.\n",
            "  Batch 3,440  of  4,516.    Elapsed: 0:44:08.\n",
            "  Batch 3,480  of  4,516.    Elapsed: 0:44:39.\n",
            "  Batch 3,520  of  4,516.    Elapsed: 0:45:10.\n",
            "  Batch 3,560  of  4,516.    Elapsed: 0:45:41.\n",
            "  Batch 3,600  of  4,516.    Elapsed: 0:46:11.\n",
            "  Batch 3,640  of  4,516.    Elapsed: 0:46:42.\n",
            "  Batch 3,680  of  4,516.    Elapsed: 0:47:13.\n",
            "  Batch 3,720  of  4,516.    Elapsed: 0:47:44.\n",
            "  Batch 3,760  of  4,516.    Elapsed: 0:48:15.\n",
            "  Batch 3,800  of  4,516.    Elapsed: 0:48:45.\n",
            "  Batch 3,840  of  4,516.    Elapsed: 0:49:16.\n",
            "  Batch 3,880  of  4,516.    Elapsed: 0:49:47.\n",
            "  Batch 3,920  of  4,516.    Elapsed: 0:50:18.\n",
            "  Batch 3,960  of  4,516.    Elapsed: 0:50:49.\n",
            "  Batch 4,000  of  4,516.    Elapsed: 0:51:19.\n",
            "  Batch 4,040  of  4,516.    Elapsed: 0:51:50.\n",
            "  Batch 4,080  of  4,516.    Elapsed: 0:52:21.\n",
            "  Batch 4,120  of  4,516.    Elapsed: 0:52:52.\n",
            "  Batch 4,160  of  4,516.    Elapsed: 0:53:23.\n",
            "  Batch 4,200  of  4,516.    Elapsed: 0:53:53.\n",
            "  Batch 4,240  of  4,516.    Elapsed: 0:54:24.\n",
            "  Batch 4,280  of  4,516.    Elapsed: 0:54:55.\n",
            "  Batch 4,320  of  4,516.    Elapsed: 0:55:26.\n",
            "  Batch 4,360  of  4,516.    Elapsed: 0:55:57.\n",
            "  Batch 4,400  of  4,516.    Elapsed: 0:56:27.\n",
            "  Batch 4,440  of  4,516.    Elapsed: 0:56:58.\n",
            "  Batch 4,480  of  4,516.    Elapsed: 0:57:29.\n",
            "\n",
            "  Average training loss: 0.11\n",
            "  Training epcoh took: 0:57:56\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.90\n",
            "  Validation took: 0:03:57\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ctuu_U7QtCd"
      },
      "source": [
        "## graficos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "id": "AQINk1h2QtCd",
        "outputId": "35cf4386-9d3b-48a4-d05b-7b6798b9fd67"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set(style='darkgrid')\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(loss_values, 'b-o')\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3tcKtxDeQtCd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}